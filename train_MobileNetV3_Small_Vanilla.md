# HÆ°á»›ng Dáº«n Training MobileNetV3-Small Vanilla (Baseline CNN)

## Giá»›i Thiá»‡u

File `train_MobileNetV3_Small_Vanilla.py` Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n **baseline CNN model** - MobileNetV3-Small **KHÃ”NG CÃ“** attention mechanism trÃªn táº­p dá»¯ liá»‡u Paddy Disease Classification.

**Má»¥c Ä‘Ã­ch cá»§a model nÃ y:**

- ğŸ¯ **Baseline Ä‘á»ƒ so sÃ¡nh**: ÄÃ¡nh giÃ¡ contribution cá»§a cÃ¡c attention mechanisms
- ğŸ“Š **Pure CNN performance**: Hiá»‡u suáº¥t cá»§a CNN thuáº§n tÃºy khÃ´ng cÃ³ attention
- âš¡ **Speed benchmark**: Äo tá»‘c Ä‘á»™ inference cá»§a backbone gá»‘c
- ğŸ”¬ **Scientific comparison**: So sÃ¡nh cÃ´ng báº±ng vá»›i 8 attention-enhanced models

**Äáº·c Ä‘iá»ƒm MobileNetV3-Small Vanilla:**

- **KhÃ´ng cÃ³ attention mechanism**: Pure depthwise separable convolutions
- **Lightest**: Ãt parameters nháº¥t (chá»‰ cÃ³ backbone + classifier)
- **Fastest training**: KhÃ´ng cÃ³ overhead tá»« attention computation
- **Baseline accuracy**: Äo accuracy ceiling mÃ  attention cÃ³ thá»ƒ improve

## Táº¡i Sao Cáº§n Baseline Model?

### **1. ÄÃ¡nh GiÃ¡ Contribution cá»§a Attention**

```python
# Náº¿u khÃ´ng cÃ³ baseline:
"BoT model Ä‘áº¡t 99.3% accuracy"  
â†’ KhÃ´ng biáº¿t bao nhiÃªu % lÃ  do backbone, bao nhiÃªu % lÃ  do attention?

# Vá»›i baseline:
Vanilla: 98.5% accuracy  â† Backbone contribution
BoT:     99.3% accuracy  
         â”€â”€â”€â”€â”€
         +0.8% â† Attention contribution! 

â†’ RÃµ rÃ ng attention giÃºp tÄƒng 0.8%!
```

---

### **2. So SÃ¡nh Cost vs Benefit**

| Model | Params | Time (ms) | Accuracy | Cost | Benefit |
|-------|--------|-----------|----------|------|---------|
| **Vanilla** | **1.53M** | **~5.0** | **98.5%** | **Baseline** | **Baseline** |
| BoT | 1.75M | 6.13 | 99.3% | +220K params, +23% time | +0.8% acc |
| ECA | 1.86M | 6.37 | 99.1% | +330K params, +27% time | +0.6% acc |
| Hybrid | 2.15M | 26.01 | 99.4% | +620K params, +420% time | +0.9% acc |

**â†’ Vanilla cho tháº¥y: Hybrid tÄƒng 0.9% accuracy nhÆ°ng cháº­m hÆ¡n 5.2x!**

---

### **3. Scientific Rigor**

Trong research, luÃ´n cáº§n **ablation study**:

```
Hypothesis: "Attention mechanisms improve accuracy"

Experiment:
â”œâ”€ Control group:  Vanilla CNN (no attention)
â””â”€ Test groups:    BoT, CA, ECA, Hybrid, ... (with attention)

Result: 
If attention models >> vanilla â†’ Hypothesis confirmed! âœ…
If attention models â‰ˆ vanilla â†’ Attention khÃ´ng cÃ³ Ã­ch âŒ
```

---

## YÃªu Cáº§u

### 1. Cáº¥u TrÃºc ThÆ° Má»¥c

```text
Paddy-Disease-Classification-final/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ metadata.csv
â”‚   â”œâ”€â”€ label2id.json
â”‚   â””â”€â”€ images/
â”œâ”€â”€ train_MobileNetV3_Small_Vanilla.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ backbones/
â”‚   â”‚       â””â”€â”€ mobilenet.py
â”‚   â”œâ”€â”€ training/
â”‚   â””â”€â”€ utils/
â””â”€â”€ results/
```

### 2. Dá»¯ Liá»‡u Cáº§n Thiáº¿t

- `data/metadata.csv`: File chá»©a thÃ´ng tin áº£nh vÃ  nhÃ£n
- `data/label2id.json`: File mapping tá»« tÃªn nhÃ£n sang ID
- `data/images/`: ThÆ° má»¥c chá»©a áº£nh training/validation

## CÃ¡ch Sá»­ Dá»¥ng

### 1. Training CÆ¡ Báº£n

```bash
python train_MobileNetV3_Small_Vanilla.py
```

### 2. Training vá»›i Tham Sá»‘ TÃ¹y Chá»‰nh

```bash
python train_MobileNetV3_Small_Vanilla.py \
    --epochs 30 \
    --batch-size 64 \
    --base-lr 5e-5 \
    --head-lr 5e-4 \
    --pretrained
```

### 3. Quick Test

```bash
python train_MobileNetV3_Small_Vanilla.py \
    --epochs 2 \
    --batch-size 16 \
    --train-limit 100 \
    --valid-limit 50 \
    --pretrained
```

## Tham Sá»‘ DÃ²ng Lá»‡nh

### Dá»¯ Liá»‡u & ÄÆ°á»ng Dáº«n

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--metadata` | `data/metadata.csv` | ÄÆ°á»ng dáº«n Ä‘áº¿n file metadata |
| `--label2id` | `data/label2id.json` | ÄÆ°á»ng dáº«n Ä‘áº¿n file label mapping |

### Cáº¥u HÃ¬nh Model

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--image-size` | 224 | KÃ­ch thÆ°á»›c áº£nh Ä‘áº§u vÃ o |
| `--dropout` | 0.1 | Dropout rate trÆ°á»›c classifier |
| `--pretrained` | False | Sá»­ dá»¥ng pretrained weights tá»« ImageNet |

### Training Configuration

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--epochs` | 30 | Sá»‘ epoch training |
| `--batch-size` | 32 | Batch size |
| `--patience` | 10 | Early stopping patience |
| `--base-lr` | 5e-5 | Learning rate cho backbone |
| `--head-lr` | 5e-4 | Learning rate cho classifier head |
| `--weight-decay` | 1e-2 | Weight decay cho optimizer |

### DataLoader Configuration

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--num-workers` | 4 | Sá»‘ workers cho DataLoader |
| `--pin-memory` | False | Pin memory trong DataLoader |

### Visualization & Logging

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--plot` | False | Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ training history |
| `--save-history` | False | LÆ°u history JSON + metrics JSON + plot PNG |

## VÃ­ Dá»¥ Thá»±c Táº¿

### 1. Training Baseline (Khuyáº¿n Nghá»‹)

```bash
python train_MobileNetV3_Small_Vanilla.py \
    --epochs 30 \
    --batch-size 64 \
    --base-lr 5e-5 \
    --head-lr 5e-4 \
    --weight-decay 1e-2 \
    --patience 10 \
    --pretrained \
    --num-workers 4 \
    --pin-memory \
    --image-size 224 \
    --save-history
```

**Káº¿t quáº£ mong Ä‘á»£i:**

- Validation Accuracy: ~98.0-98.5%
- Training time: ~25-35 phÃºt (GPU GTX 1660 SUPER)
- Model size: ~5.84 MB (smallest!)
- **Inference: ~5.0 ms/batch** âš¡ **FASTEST POSSIBLE**

---

### 2. Training Táº¥t Cáº£ Models Äá»ƒ So SÃ¡nh

```bash
# Step 1: Train Baseline (QUAN TRá»ŒNG!)
python train_MobileNetV3_Small_Vanilla.py \
    --epochs 30 --batch-size 64 --pretrained \
    --num-workers 4 --image-size 224 --save-history

# Step 2: Train Attention Models
python train_MobileNetV3_Small_BoT.py \
    --epochs 30 --batch-size 64 --pretrained \
    --num-workers 4 --image-size 224 --save-history

python train_MobileNetV3_Small_CA.py \
    --epochs 30 --batch-size 64 --pretrained \
    --num-workers 4 --image-size 224 --save-history

python train_MobileNetV3_Small_ECA.py \
    --epochs 30 --batch-size 64 --pretrained \
    --num-workers 4 --image-size 224 --save-history

# Step 3: So sÃ¡nh results/
```

---

### 3. Parallel Training (3 Models Äá»“ng Thá»i)

```bash
# Terminal 1: Vanilla Baseline
python train_MobileNetV3_Small_Vanilla.py \
    --epochs 30 --batch-size 64 --pretrained \
    --num-workers 3 --image-size 224 --save-history &

# Terminal 2: ECA (Fastest attention)
python train_MobileNetV3_Small_ECA.py \
    --epochs 30 --batch-size 64 --pretrained \
    --num-workers 3 --image-size 224 --save-history &

# Terminal 3: BoT (Best accuracy)
python train_MobileNetV3_Small_BoT.py \
    --epochs 30 --batch-size 48 --pretrained \
    --num-workers 3 --image-size 224 --save-history &

wait
```

---

## Äáº§u Ra

### 1. Model Checkpoint

- `MobileNetV3_Small_Vanilla_best.pt` - Best model

### 2. Results Files

```text
results/
â””â”€â”€ MobileNetV3_Small_Vanilla_06_10_2025_1600/
    â”œâ”€â”€ history.json
    â”œâ”€â”€ metrics.json
    â””â”€â”€ training_plot.png
```

### 3. Expected Results

Vá»›i cáº¥u hÃ¬nh tá»‘i Æ°u (pretrained, 30 epochs, batch_size=64):

- **Validation Accuracy**: ~98.0-98.5%
- **F1-Score**: ~98.0-98.5%
- **Inference Speed**: ~4,900 FPS (batch=16) âš¡ **FASTEST**
- **Model Size**: ~5.84 MB **SMALLEST**
- **Parameters**: ~1.53M **LIGHTEST**
- **Training Time**: ~25-35 phÃºt (GTX 1660 SUPER)

---

## So SÃ¡nh vá»›i Táº¥t Cáº£ Models

### **Báº£ng So SÃ¡nh Äáº§y Äá»§ (9 Models)**

| # | Model | Params | Size (MB) | Time (ms) | Accuracy | Gain vs Vanilla | Cost vs Vanilla |
|---|-------|--------|-----------|-----------|----------|-----------------|-----------------|
| **0** | **Vanilla** | **1.53M** | **5.84** | **~5.0** âš¡ | **~98.5%** | **Baseline** | **Baseline** |
| 1 | BoT | 1.75M | 6.69 | 6.13 | ~99.3% | **+0.8%** | +220K params, +23% time |
| 2 | BoT_Linear | 1.75M | 6.69 | 6.98 | ~99.2% | **+0.7%** | +220K params, +40% time |
| 3 | CA | 1.92M | 7.32 | 8.81 | ~99.2% | **+0.7%** | +390K params, +76% time |
| 4 | ECA | 1.86M | 7.08 | 6.37 | ~99.1% | **+0.6%** | +330K params, +27% time |
| 5 | Hybrid | 2.15M | 8.19 | 26.01 | ~99.4% | **+0.9%** | +620K params, +420% time |
| 6 | MobileViT_XXS | 0.95M | 3.64 | 19.48 | ~99.0% | +0.5% | -580K params, +290% time |
| 7 | ResNet18_BoT | 11.36M | 43.34 | 14.97 | ~99.3% | +0.8% | +9.83M params, +199% time |
| 8 | ResNet18_BoTLinear | 11.36M | 43.34 | 14.93 | ~99.3% | +0.8% | +9.83M params, +199% time |

---

### **Insights tá»« So SÃ¡nh**

#### **1. Accuracy Improvement Analysis**

```text
Attention Mechanisms Contribution:
â”œâ”€ Best:     Hybrid (+0.9%)    â†’ Worth it náº¿u khÃ´ng care speed
â”œâ”€ Good:     BoT (+0.8%)       â†’ Best balance (accuracy vs speed)
â”œâ”€ OK:       CA, Linear (+0.7%) â†’ Decent improvement
â””â”€ Minimal:  ECA (+0.6%)       â†’ Fastest, acceptable tradeoff
```

#### **2. Speed Analysis**

```text
Vanilla:  5.0 ms   â† BASELINE (fastest possible)
ECA:      6.37 ms  (+27%)  â† Minimal overhead
BoT:      6.13 ms  (+23%)  â† Surprisingly fast!
CA:       8.81 ms  (+76%)  â† Moderate overhead
Hybrid:   26.01 ms (+420%) â† Heavy computation
```

**â†’ BoT vÃ  ECA cÃ³ best speed-accuracy tradeoff!**

#### **3. Cost-Benefit Analysis**

**Most Efficient (ROI):**

1. **BoT**: +0.8% accuracy, +23% time â†’ **0.035% gain per 1% time**
2. **ECA**: +0.6% accuracy, +27% time â†’ **0.022% gain per 1% time**
3. **Linear**: +0.7% accuracy, +40% time â†’ **0.018% gain per 1% time**

**Least Efficient:**

- **Hybrid**: +0.9% accuracy, +420% time â†’ **0.002% gain per 1% time**

---

## Khi NÃ o Chá»n Vanilla?

### **âœ… CHá»ŒN VANILLA KHI:**

1. **Extreme Speed Required**
   - Real-time video processing (>200 FPS)
   - Embedded systems vá»›i limited compute
   - Battery-powered devices

2. **Baseline Experiment**
   - Research paper ablation study
   - Evaluating attention contributions
   - Scientific comparison

3. **98.5% Accuracy Äá»§**
   - Task khÃ´ng cáº§n perfect accuracy
   - Cost-sensitive deployment
   - Large-scale serving vá»›i tight latency budget

4. **Training Resources Limited**
   - Nhanh nháº¥t Ä‘á»ƒ train (25-35 phÃºt)
   - Ãt VRAM nháº¥t
   - Dá»… debug nháº¥t

---

### **âŒ KHÃ”NG CHá»ŒN VANILLA KHI:**

1. **Accuracy Critical** â†’ DÃ¹ng Hybrid hoáº·c BoT
2. **CÃ³ Äá»§ Resources** â†’ DÃ¹ng attention models
3. **Cáº§n Interpretability** â†’ Attention maps giÃºp explain
4. **Research Contribution** â†’ Vanilla quÃ¡ basic

---

## Kiáº¿n TrÃºc Model

### MobileNetV3-Small Vanilla

```text
Input (3x224x224)
    â†“
[MobileNetV3-Small Backbone] (pretrained on ImageNet)
    â”‚
    â”œâ”€ Initial Conv (16 channels)
    â”œâ”€ Inverted Residual Blocks (MBConv)
    â”‚   â”œâ”€ Depthwise Separable Convolutions
    â”‚   â”œâ”€ Squeeze-Excitation (built-in SE modules)
    â”‚   â””â”€ Hard-Swish activations
    â””â”€ Final Conv (576 channels)
    â†“
[AdaptiveAvgPool2d] â†’ (B, 576, 1, 1)
    â†“
[Dropout 0.1]
    â†“
[Linear Classifier] â†’ (B, num_classes)
```

**Äáº·c Ä‘iá»ƒm:**

- **Pure CNN**: Chá»‰ cÃ³ convolutions, khÃ´ng cÃ³ attention
- **Depthwise Separable**: Efficient convolutions
- **Built-in SE**: MobileNetV3 cÃ³ SE modules (nhÆ°ng khÃ¡c vá»›i external attention)
- **Lightest**: 1.53M params
- **Fastest**: ~5.0 ms inference

---

## Tips & Best Practices

### 1. Training Strategy

```bash
# LuÃ´n train Vanilla TRÆ¯á»šC Ä‘á»ƒ cÃ³ baseline!
python train_MobileNetV3_Small_Vanilla.py --pretrained --save-history

# Sau Ä‘Ã³ train attention models
# So sÃ¡nh vá»›i baseline Ä‘á»ƒ evaluate attention contribution
```

### 2. Hyperparameters

**Vanilla dÃ¹ng CÃ™NG hyperparameters vá»›i attention models:**

- `--base-lr 5e-5`, `--head-lr 5e-4`
- `--batch-size 64`
- `--weight-decay 1e-2`

**â†’ Äáº£m báº£o fair comparison!**

### 3. Expected Performance

```python
# Typical results:
Vanilla: 98.0-98.5% accuracy
BoT:     99.2-99.4% accuracy
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         +0.7-0.9% improvement from attention

# If attention models < 98.5%:
â†’ Something wrong with attention implementation!

# If attention models >> 99.5%:
â†’ Possible overfitting, check regularization
```

---

## Troubleshooting

### Vanilla Accuracy QuÃ¡ Tháº¥p (<97%)

**NguyÃªn nhÃ¢n:**

- KhÃ´ng dÃ¹ng pretrained weights
- Learning rate quÃ¡ cao/tháº¥p
- Data augmentation quÃ¡ máº¡nh

**Giáº£i phÃ¡p:**

```bash
# Äáº£m báº£o dÃ¹ng pretrained
python train_MobileNetV3_Small_Vanilla.py --pretrained

# Kiá»ƒm tra learning rate
python train_MobileNetV3_Small_Vanilla.py \
    --base-lr 5e-5 \
    --head-lr 5e-4
```

---

### Attention Models KhÃ´ng Tá»‘t HÆ¡n Vanilla

**NguyÃªn nhÃ¢n:**

- Attention modules cÃ³ bug
- Overfitting trÃªn attention
- Learning rate khÃ´ng phÃ¹ há»£p cho attention

**Giáº£i phÃ¡p:**

```bash
# Test gradient flow
python test_all_models.ipynb  # Run gradient flow tests

# TÄƒng regularization cho attention models
python train_MobileNetV3_Small_BoT.py \
    --dropout 0.2 \
    --weight-decay 2e-2
```

---

## Benchmark Script

Táº¡o script Ä‘á»ƒ so sÃ¡nh táº¥t cáº£ models:

```bash
#!/bin/bash
# compare_all_models.sh

echo "="*80
echo "TRAINING ALL 9 MODELS FOR COMPARISON"
echo "="*80

# 1. Baseline
echo "[1/9] Training Vanilla Baseline..."
python train_MobileNetV3_Small_Vanilla.py \
    --epochs 30 --batch-size 64 --pretrained \
    --num-workers 4 --image-size 224 --save-history

# 2-9. Attention Models
for model in BoT BoT_Linear CA ECA Hybrid; do
    echo "[Training MobileNetV3_Small_$model..."
    python train_MobileNetV3_Small_$model.py \
        --epochs 30 --batch-size 64 --pretrained \
        --num-workers 4 --image-size 224 --save-history
done

echo "="*80
echo "TRAINING COMPLETED! Check results/ directory"
echo "="*80

# Compare results
python scripts/compare_results.py
```

---

## Tham Kháº£o

- Model Implementation: `src/models/backbones/mobilenet.py` (class `MobileNetV3_Small_Vanilla`)
- Training Logic: `src/training/train.py`
- MobileNetV3 Paper: "Searching for MobileNetV3" (ICCV 2019)
- Baseline: Pure CNN without external attention mechanisms

---

## License

MIT License
