# HÆ°á»›ng Dáº«n Training MobileNetV3-Small Hybrid

## Giá»›i Thiá»‡u

File `train_MobileNetV3_Small_Hybrid.py` Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh MobileNetV3-Small Hybrid vá»›i káº¿t há»£p **Coordinate Attention (CA)** vÃ  **BoT (Bottleneck Transformer)** block trÃªn táº­p dá»¯ liá»‡u Paddy Disease Classification.

### Äiá»ƒm KhÃ¡c Biá»‡t vá»›i BoT Model

| Äáº·c Ä‘iá»ƒm | MobileNetV3_Small_BoT | MobileNetV3_Small_Hybrid |
|----------|----------------------|--------------------------|
| **Attention Blocks** | BoT only | CA + BoT (stacked) |
| **Default Dropout** | 0.1 | 0.2 |
| **Complexity** | Lower | Higher |
| **Parameters** | ~1.75M | ~1.76M |
| **Accuracy** | ~99.3% | Potentially higher |
| **Training Time** | Standard | Slightly longer |

## YÃªu Cáº§u

### 1. Cáº¥u TrÃºc ThÆ° Má»¥c

Äáº£m báº£o cáº¥u trÃºc thÆ° má»¥c nhÆ° sau:

```
Paddy-Disease-Classification-final/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ metadata.csv
â”‚   â”œâ”€â”€ label2id.json
â”‚   â””â”€â”€ images/
â”œâ”€â”€ train_MobileNetV3_Small_Hybrid.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ attention/
â”‚   â”‚   â”‚   â”œâ”€â”€ botblock.py
â”‚   â”‚   â”‚   â””â”€â”€ cablock.py
â”‚   â”‚   â””â”€â”€ backbones/
â”‚   â”‚       â””â”€â”€ mobilenet.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â””â”€â”€ param_groups.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data/
â”‚       â””â”€â”€ metrics/
â””â”€â”€ results/
```

### 2. Dá»¯ Liá»‡u Cáº§n Thiáº¿t

- `data/metadata.csv`: File chá»©a thÃ´ng tin áº£nh vÃ  nhÃ£n
- `data/label2id.json`: File mapping tá»« tÃªn nhÃ£n sang ID
- `data/images/`: ThÆ° má»¥c chá»©a áº£nh training/validation

## CÃ¡ch Sá»­ Dá»¥ng

### 1. Training CÆ¡ Báº£n

```bash
python train_MobileNetV3_Small_Hybrid.py
```

### 2. Training vá»›i Tham Sá»‘ TÃ¹y Chá»‰nh

```bash
python train_MobileNetV3_Small_Hybrid.py \
    --epochs 30 \
    --batch-size 32 \
    --heads 4 \
    --reduction 16 \
    --dropout 0.2 \
    --pretrained
```

### 3. Quick Test (Training Nhanh vá»›i Dá»¯ Liá»‡u Giá»›i Háº¡n)

```bash
python train_MobileNetV3_Small_Hybrid.py \
    --epochs 2 \
    --batch-size 16 \
    --train-limit 100 \
    --valid-limit 50 \
    --pretrained
```

## Tham Sá»‘ DÃ²ng Lá»‡nh

### Dá»¯ Liá»‡u & ÄÆ°á»ng Dáº«n

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--metadata` | `data/metadata.csv` | ÄÆ°á»ng dáº«n Ä‘áº¿n file metadata |
| `--label2id` | `data/label2id.json` | ÄÆ°á»ng dáº«n Ä‘áº¿n file label mapping |

### Cáº¥u HÃ¬nh Model

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--image-size` | 224 | KÃ­ch thÆ°á»›c áº£nh Ä‘áº§u vÃ o |
| `--heads` | 4 | Sá»‘ attention heads trong BoT block |
| `--reduction` | 16 | Reduction ratio cho Coordinate Attention (khÃ¡c vá»›i BoT: khÃ´ng cÃ³ tham sá»‘ nÃ y) |
| `--dropout` | 0.2 | Dropout rate trÆ°á»›c classifier (cao hÆ¡n BoT: 0.1) |
| `--pretrained` | False | Sá»­ dá»¥ng pretrained weights tá»« ImageNet |

### Training Configuration

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--epochs` | 30 | Sá»‘ epoch training (nhiá»u hÆ¡n default cá»§a BoT: 10) |
| `--batch-size` | 32 | Batch size |
| `--patience` | 10 | Early stopping patience (cao hÆ¡n BoT: 5) |
| `--base-lr` | 5e-5 | Learning rate cho backbone (tháº¥p hÆ¡n BoT: 1e-4) |
| `--head-lr` | 5e-4 | Learning rate cho classifier head (tháº¥p hÆ¡n BoT: 1e-3) |
| `--weight-decay` | 1e-2 | Weight decay cho optimizer |
| `--scheduler-tmax` | None | T_max cho CosineAnnealingLR |

### DataLoader Configuration

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--num-workers` | 4 | Sá»‘ workers cho DataLoader |
| `--pin-memory` | False | Pin memory trong DataLoader |

### Debug & Testing

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--train-limit` | None | Giá»›i háº¡n sá»‘ máº«u training (cho test nhanh) |
| `--valid-limit` | None | Giá»›i háº¡n sá»‘ máº«u validation (cho test nhanh) |
| `--model-name` | MobileNetV3_Small_Hybrid | TÃªn model cho logging/checkpoint |
| `--device` | auto | Device (cpu/cuda) |
| `--seed` | 42 | Random seed |

### Visualization & Logging

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--plot` | False | Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ training history sau khi train |
| `--save-history` | False | Tá»± Ä‘á»™ng lÆ°u: history JSON + metrics JSON + biá»ƒu Ä‘á»“ PNG (DPI 300) |

## VÃ­ Dá»¥ Thá»±c Táº¿

### 1. Training Full Dataset vá»›i Pretrained Weights (Khuyáº¿n Nghá»‹)

```bash
python train_MobileNetV3_Small_Hybrid.py \
    --epochs 30 \
    --batch-size 64 \
    --base-lr 5e-5 \
    --head-lr 5e-4 \
    --heads 4 \
    --reduction 16 \
    --dropout 0.2 \
    --weight-decay 1e-2 \
    --patience 10 \
    --pretrained \
    --num-workers 8 \
    --pin-memory \
    --image-size 224 \
    --save-history
```

**Káº¿t quáº£ mong Ä‘á»£i:**

- Validation Accuracy: ~99.3-99.5% (cÃ³ thá»ƒ cao hÆ¡n BoT model)
- Training time: ~35-50 phÃºt (GPU T4, lÃ¢u hÆ¡n BoT ~10-15%)
- **Output files:**
  - `MobileNetV3_Small_Hybrid_best.pt` - Model checkpoint
  - `results/MobileNetV3_Small_Hybrid_history.json` - Training history
  - `results/MobileNetV3_Small_Hybrid_metrics.json` - Final metrics
  - `results/MobileNetV3_Small_Hybrid_training_plot.png` - Training curves (DPI 300)

### 2. Training tá»« Scratch

```bash
python train_MobileNetV3_Small_Hybrid.py \
    --epochs 50 \
    --batch-size 32 \
    --base-lr 1e-3 \
    --head-lr 1e-2 \
    --dropout 0.3 \
    --weight-decay 1e-2 \
    --patience 15 \
    --num-workers 4
```

**LÆ°u Ã½:** Training tá»« scratch vá»›i Hybrid model cáº§n:

- Nhiá»u epochs hÆ¡n (50-70)
- Dropout cao hÆ¡n (0.3) Ä‘á»ƒ trÃ¡nh overfitting
- Patience cao hÆ¡n (15-20)

### 3. Thá»­ Nghiá»‡m CÃ¡c Reduction Ratios

```bash
# Reduction = 8 (nhiá»u parameters hÆ¡n, cháº­m hÆ¡n)
python train_MobileNetV3_Small_Hybrid.py \
    --epochs 30 \
    --batch-size 48 \
    --reduction 8 \
    --pretrained

# Reduction = 32 (Ã­t parameters hÆ¡n, nhanh hÆ¡n)
python train_MobileNetV3_Small_Hybrid.py \
    --epochs 30 \
    --batch-size 64 \
    --reduction 32 \
    --pretrained
```

### 4. Training vá»›i GPU Cá»¥ Thá»ƒ

```bash
CUDA_VISIBLE_DEVICES=0 python train_MobileNetV3_Small_Hybrid.py \
    --epochs 30 \
    --batch-size 32 \
    --pretrained \
    --device cuda
```

### 5. Training trÃªn CPU (KhÃ´ng khuyáº¿n nghá»‹)

```bash
python train_MobileNetV3_Small_Hybrid.py \
    --epochs 5 \
    --batch-size 8 \
    --device cpu \
    --num-workers 2 \
    --train-limit 1000
```

### 6. Training vá»›i Auto-Save vÃ  Display

```bash
python train_MobileNetV3_Small_Hybrid.py \
    --epochs 30 \
    --batch-size 64 \
    --pretrained \
    --save-history \
    --plot
```

**Vá»›i `--save-history`, tá»± Ä‘á»™ng lÆ°u:**

- âœ… `results/MobileNetV3_Small_Hybrid_history.json` - Training history
- âœ… `results/MobileNetV3_Small_Hybrid_metrics.json` - Final metrics
- âœ… `results/MobileNetV3_Small_Hybrid_training_plot.png` - High-res plot (DPI 300)

**Vá»›i `--plot`, thÃªm:**

- ğŸ“Š Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ realtime

### 7. Fine-tuning vá»›i Dropout Cao

```bash
python train_MobileNetV3_Small_Hybrid.py \
    --epochs 25 \
    --batch-size 32 \
    --base-lr 1e-5 \
    --head-lr 1e-4 \
    --dropout 0.3 \
    --pretrained \
    --patience 12
```

## Äáº§u Ra

### 1. Model Checkpoint

Checkpoint Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c gá»‘c:

- `MobileNetV3_Small_Hybrid_best.pt` - Best model

### 2. Results Files (vá»›i `--save-history`)

Tá»± Ä‘á»™ng lÆ°u trong `results/`:

```plaintext
results/
â”œâ”€â”€ MobileNetV3_Small_Hybrid_history.json
â”œâ”€â”€ MobileNetV3_Small_Hybrid_metrics.json
â””â”€â”€ MobileNetV3_Small_Hybrid_training_plot.png
```

### 3. Console Output

Sau khi training, metrics sáº½ Ä‘Æ°á»£c in ra console:

```plaintext
Training finished. Metrics:
  model_name: MobileNetV3_Small_Hybrid
  size_mb: 6.70
  valid_acc: 0.9940
  valid_f1: 0.9941
  fps: 3850.45
  num_params: 1760000
  ckpt_path: MobileNetV3_Small_Hybrid_best.pt
```

### 3. Training History

Training history Ä‘Æ°á»£c tráº£ vá» dÆ°á»›i dáº¡ng dictionary chá»©a:

- `train_loss`: List cÃ¡c giÃ¡ trá»‹ loss theo epoch
- `valid_loss`: List cÃ¡c giÃ¡ trá»‹ validation loss
- `train_acc`: List cÃ¡c giÃ¡ trá»‹ accuracy
- `valid_acc`: List cÃ¡c giÃ¡ trá»‹ validation accuracy
- `learning_rates`: List cÃ¡c learning rates theo epoch

### 4. Expected Results

Vá»›i cáº¥u hÃ¬nh tá»‘i Æ°u (pretrained, 30 epochs, batch_size=64), báº¡n cÃ³ thá»ƒ Ä‘áº¡t:

- **Validation Accuracy**: ~99.3-99.5%
- **F1-Score**: ~99.4%
- **Inference Speed**: ~3,850 FPS (cháº­m hÆ¡n BoT ~3%)
- **Model Size**: ~6.70 MB (lá»›n hÆ¡n BoT ~0.03 MB)
- **Training Time**: ~35-50 phÃºt (GPU T4)

## Kiáº¿n TrÃºc Model

### MobileNetV3-Small Hybrid (CA + BoT)

```plaintext
Input (3x224x224)
    â†“
[MobileNetV3-Small Backbone] (pretrained on ImageNet)
    â†“
Feature Maps (576 channels)
    â†“
[Coordinate Attention Block]
    â”œâ”€ X-Direction Attention (reduction=16)
    â””â”€ Y-Direction Attention (reduction=16)
    â†“
Feature Maps (576 channels)
    â†“
[BoTNet Block] (Self-Attention with 4 heads)
    â”œâ”€ Multi-Head Self Attention
    â””â”€ Relative Position Encoding
    â†“
Feature Maps (576 channels)
    â†“
[AdaptiveAvgPool2d]
    â†“
[Dropout 0.2]
    â†“
[Linear Classifier] â†’ Output (num_classes)
```

**Äáº·c Ä‘iá»ƒm:**

- **Backbone**: MobileNetV3-Small (efficient, lightweight)
- **Attention Stack**:
  - CABlock: Spatial attention theo cáº£ 2 chiá»u X vÃ  Y
  - BoTBlock: Multi-head self-attention vá»›i relative position encoding
- **Parameters**: ~1.76M (chá»‰ tÄƒng ~10K so vá»›i BoT model)
- **Size**: ~6.70 MB
- **Optimal for**:
  - Cáº§n accuracy cao nháº¥t cÃ³ thá»ƒ
  - CÃ³ thá»ƒ cháº¥p nháº­n tÄƒng nháº¹ complexity
  - Cáº§n cáº£ spatial vÃ  self-attention

## Troubleshooting

### Lá»—i: "FileNotFoundError: metadata file not found"

**Giáº£i phÃ¡p:**

```bash
# Chá»‰ Ä‘á»‹nh Ä‘Ãºng Ä‘Æ°á»ng dáº«n
python train_MobileNetV3_Small_Hybrid.py \
    --metadata path/to/your/metadata.csv \
    --label2id path/to/your/label2id.json
```

### Lá»—i: "ModuleNotFoundError: No module named 'src'"

**Giáº£i phÃ¡p:**

- Äáº£m báº£o cháº¡y tá»« thÆ° má»¥c gá»‘c cá»§a project
- Kiá»ƒm tra cáº¥u trÃºc thÆ° má»¥c `src/` tá»“n táº¡i
- Kiá»ƒm tra file `src/models/attention/cablock.py` vÃ  `botblock.py` tá»“n táº¡i

### Out of Memory (OOM)

**Giáº£i phÃ¡p:**

```bash
# Giáº£m batch size (Hybrid model tá»‘n memory hÆ¡n BoT ~5-10%)
python train_MobileNetV3_Small_Hybrid.py --batch-size 16

# Hoáº·c giáº£m image size
python train_MobileNetV3_Small_Hybrid.py --image-size 192

# Hoáº·c giáº£m reduction ratio
python train_MobileNetV3_Small_Hybrid.py --reduction 32
```

### Training QuÃ¡ Cháº­m

**Giáº£i phÃ¡p:**

```bash
# TÄƒng sá»‘ workers
python train_MobileNetV3_Small_Hybrid.py \
    --num-workers 8 \
    --pin-memory

# Hoáº·c test vá»›i subset nhá»
python train_MobileNetV3_Small_Hybrid.py \
    --train-limit 1000 \
    --valid-limit 200

# Hoáº·c tÄƒng reduction ratio (giáº£m complexity)
python train_MobileNetV3_Small_Hybrid.py --reduction 32
```

### Overfitting

**Giáº£i phÃ¡p:**

```bash
# TÄƒng dropout
python train_MobileNetV3_Small_Hybrid.py --dropout 0.3

# TÄƒng weight decay
python train_MobileNetV3_Small_Hybrid.py --weight-decay 2e-2

# Giáº£m learning rate
python train_MobileNetV3_Small_Hybrid.py --base-lr 1e-5 --head-lr 1e-4
```

## Tips & Best Practices

### 1. Chá»n Learning Rate

- **Pretrained model**: `base_lr=5e-5` Ä‘áº¿n `1e-5`, `head_lr=5e-4` Ä‘áº¿n `1e-4`
  - Tháº¥p hÆ¡n BoT vÃ¬ model phá»©c táº¡p hÆ¡n, dá»… diverge
- **From scratch**: `base_lr=5e-4` Ä‘áº¿n `1e-3`, `head_lr=5e-3` Ä‘áº¿n `1e-2`
  - CÅ©ng tháº¥p hÆ¡n BoT tá»« scratch

### 2. Chá»n Reduction Ratio

- **reduction=8**: Nhiá»u parameters, accuracy cao hÆ¡n, cháº­m hÆ¡n, dá»… overfit
- **reduction=16**: CÃ¢n báº±ng tá»‘t (khuyáº¿n nghá»‹)
- **reduction=32**: Ãt parameters, nhanh hÆ¡n, accuracy cÃ³ thá»ƒ tháº¥p hÆ¡n

### 3. Batch Size

- **GPU 8GB**: batch_size=48-64 (giáº£m 10-20% so vá»›i BoT)
- **GPU 4GB**: batch_size=16-24
- **CPU**: batch_size=4-8 (khÃ´ng khuyáº¿n nghá»‹)

### 4. Early Stopping

- Sá»­ dá»¥ng `--patience 10-15` (cao hÆ¡n BoT vÃ¬ cáº§n nhiá»u thá»i gian converge)
- Model phá»©c táº¡p hÆ¡n nÃªn cáº§n patience cao hÆ¡n

### 5. Dropout

- **Default**: 0.2 (Ä‘Ã£ tÄƒng so vá»›i BoT: 0.1)
- **If overfitting**: 0.3-0.4
- **If underfitting**: 0.1-0.15

### 6. Image Size

- **224x224**: Standard, khuyáº¿n nghá»‹
- **192x192**: Nhanh hÆ¡n ~30%, accuracy giáº£m ~0.5%
- **256x256**: Cháº­m hÆ¡n ~30%, cÃ³ thá»ƒ tÄƒng accuracy ~0.3%

### 7. Monitoring

Theo dÃµi cÃ¡c chá»‰ sá»‘ trong quÃ¡ trÃ¬nh training:

- **Loss giáº£m Ä‘á»u Ä‘áº·n**: Good, model Ä‘ang há»c
- **Loss tÄƒng sau vÃ i epochs**: Overfitting hoáº·c learning rate cao
- **Loss dao Ä‘á»™ng máº¡nh**: Learning rate quÃ¡ cao, giáº£m xuá»‘ng
- **Accuracy khÃ´ng cáº£i thiá»‡n**:
  - Learning rate quÃ¡ tháº¥p
  - Cáº§n tÄƒng patience
  - Model cÃ³ thá»ƒ Ä‘Ã£ converge

### 8. So SÃ¡nh vá»›i BoT

Khi nÃ o dÃ¹ng Hybrid thay vÃ¬ BoT:

- âœ… **DÃ¹ng Hybrid khi**: Cáº§n accuracy cao nháº¥t, cÃ³ GPU Ä‘á»§ máº¡nh, khÃ´ng quÃ¡ quan tÃ¢m tá»‘c Ä‘á»™
- âœ… **DÃ¹ng BoT khi**: Cáº§n tá»‘c Ä‘á»™ nhanh, deploy trÃªn mobile/edge devices, accuracy ~99% lÃ  Ä‘á»§

## Performance Comparison

| Metric | MobileNetV3_Small_BoT | MobileNetV3_Small_Hybrid |
|--------|----------------------|--------------------------|
| **Accuracy** | ~99.33% | ~99.40-99.50% |
| **F1-Score** | ~99.33% | ~99.41% |
| **FPS** | ~3,969 | ~3,850 (-3%) |
| **Size** | ~6.67 MB | ~6.70 MB (+0.03 MB) |
| **Parameters** | ~1.75M | ~1.76M (+10K) |
| **Training Time** | ~30-45 min | ~35-50 min (+15%) |
| **Memory Usage** | Standard | +5-10% |

## Tham Kháº£o

- Model Implementation: `src/models/backbones/mobilenet.py` (class `MobileNetV3_Small_Hybrid`)
- Training Logic: `src/training/train.py`
- Data Loading: `src/utils/data/loading.py`
- Coordinate Attention: `src/models/attention/cablock.py`
- BoTNet Block: `src/models/attention/botblock.py`

## Related Files

- `train_MobileNetV3_Small_BoT.py` - Training script cho BoT-only model
- `train_MobileNetV3_Small_BoT.md` - Documentation cho BoT model

## License

MIT License
