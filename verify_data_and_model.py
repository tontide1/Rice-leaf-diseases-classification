"""Script ƒë·ªÉ verify data preprocessing v√† test model forward pass."""

import sys
from pathlib import Path
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

# Th√™m src v√†o path
ROOT_DIR = Path(__file__).resolve().parent
SRC_DIR = ROOT_DIR / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

from src.models.backbones import EfficientNet_Lite0_CA
from src.utils.data import TransformConfig, build_datasets


def verify_data():
    """Ki·ªÉm tra data c√≥ NaN/Inf kh√¥ng."""
    print("\n" + "="*60)
    print("VERIFY DATA PREPROCESSING")
    print("="*60)
    
    # Load dataset
    cfg = TransformConfig(image_size=224)
    datasets = build_datasets(
        metadata_path=ROOT_DIR / "data/metadata.csv",
        label2id_path=ROOT_DIR / "data/label2id.json",
        cfg=cfg,
        splits=("train",),
    )
    
    train_dataset = datasets["train"]
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
    
    print(f"‚úì Dataset loaded: {len(train_dataset)} samples")
    print(f"‚úì Number of classes: {len(train_dataset.label2id)}")
    
    # Ki·ªÉm tra m·ªôt v√†i batch
    print("\nKi·ªÉm tra 3 batch ƒë·∫ßu ti√™n...")
    for i, (images, labels) in enumerate(train_loader):
        if i >= 3:
            break
        
        print(f"\n  Batch {i+1}:")
        print(f"    - Shape: {images.shape}")
        print(f"    - Dtype: {images.dtype}")
        print(f"    - Min: {images.min().item():.4f}, Max: {images.max().item():.4f}")
        print(f"    - Mean: {images.mean().item():.4f}, Std: {images.std().item():.4f}")
        print(f"    - Has NaN: {torch.isnan(images).any().item()}")
        print(f"    - Has Inf: {torch.isinf(images).any().item()}")
        print(f"    - Labels shape: {labels.shape}, Min: {labels.min().item()}, Max: {labels.max().item()}")
    
    print("\n‚úÖ Data verification completed!")
    return True


def verify_model_forward():
    """Ki·ªÉm tra model forward pass v·ªõi random input."""
    print("\n" + "="*60)
    print("VERIFY MODEL FORWARD PASS")
    print("="*60)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"‚úì Device: {device}")
    
    # T·∫°o model
    model = EfficientNet_Lite0_CA(
        num_classes=10,  # Paddy dataset c√≥ 10 classes
        reduction=16,
        pretrained=False,  # Kh√¥ng d√πng pretrained ƒë·ªÉ test init
        dropout=0.2,
    ).to(device)
    
    print(f"‚úì Model created: {sum(p.numel() for p in model.parameters())/1e6:.2f}M params")
    
    # Test forward pass v·ªõi random input
    batch_size = 8
    x = torch.randn(batch_size, 3, 224, 224).to(device)
    
    print(f"\n‚úì Input shape: {x.shape}")
    print(f"  - Min: {x.min().item():.4f}, Max: {x.max().item():.4f}")
    
    # Forward pass
    with torch.no_grad():
        output = model(x)
    
    print(f"\n‚úì Output shape: {output.shape}")
    print(f"  - Min: {output.min().item():.4f}, Max: {output.max().item():.4f}")
    print(f"  - Has NaN: {torch.isnan(output).any().item()}")
    print(f"  - Has Inf: {torch.isinf(output).any().item()}")
    
    # Test backward pass
    criterion = nn.CrossEntropyLoss()
    labels = torch.randint(0, 10, (batch_size,)).to(device)
    loss = criterion(output, labels)
    
    print(f"\n‚úì Loss: {loss.item():.4f}")
    print(f"  - Has NaN: {torch.isnan(loss).any().item()}")
    print(f"  - Has Inf: {torch.isinf(loss).any().item()}")
    
    # Test backward
    loss.backward()
    
    # Ki·ªÉm tra gradients
    has_nan_grad = False
    has_inf_grad = False
    max_grad = 0.0
    
    for name, param in model.named_parameters():
        if param.grad is not None:
            if torch.isnan(param.grad).any():
                has_nan_grad = True
                print(f"  ‚ö† NaN gradient in: {name}")
            if torch.isinf(param.grad).any():
                has_inf_grad = True
                print(f"  ‚ö† Inf gradient in: {name}")
            max_grad = max(max_grad, param.grad.abs().max().item())
    
    print(f"\n‚úì Gradient check:")
    print(f"  - Has NaN gradients: {has_nan_grad}")
    print(f"  - Has Inf gradients: {has_inf_grad}")
    print(f"  - Max gradient magnitude: {max_grad:.4f}")
    
    if not has_nan_grad and not has_inf_grad:
        print("\n‚úÖ Model forward/backward pass OK!")
        return True
    else:
        print("\n‚ùå Model has gradient issues!")
        return False


def main():
    """Ch·∫°y t·∫•t c·∫£ verification."""
    print("\n" + "="*60)
    print("DATA & MODEL VERIFICATION")
    print("="*60)
    
    # Verify data
    data_ok = verify_data()
    
    # Verify model
    model_ok = verify_model_forward()
    
    # T·ªïng k·∫øt
    print("\n" + "="*60)
    print("SUMMARY")
    print("="*60)
    print(f"  Data: {'‚úÖ OK' if data_ok else '‚ùå FAILED'}")
    print(f"  Model: {'‚úÖ OK' if model_ok else '‚ùå FAILED'}")
    print("="*60 + "\n")
    
    if data_ok and model_ok:
        print("üéâ T·∫•t c·∫£ ƒë·ªÅu OK! C√≥ th·ªÉ b·∫Øt ƒë·∫ßu training v·ªõi config m·ªõi.")
    else:
        print("‚ö† C√≥ v·∫•n ƒë·ªÅ c·∫ßn fix tr∆∞·ªõc khi training!")


if __name__ == "__main__":
    main()
