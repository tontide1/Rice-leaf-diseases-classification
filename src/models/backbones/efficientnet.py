"""EfficientNetV2 backbones cho Paddy Disease Classification.

EfficientNetV2 lÃ  tháº¿ há»‡ backbone tiÃªn tiáº¿n vá»›i:
- Fused-MBConv blocks: nhanh hÆ¡n MBConv truyá»n thá»‘ng
- Progressive Learning: train nhanh vÃ  á»•n Ä‘á»‹nh hÆ¡n
- Optimized cho resolution 224x224 (perfect cho dataset nÃ y)
"""

import torch
import torch.nn as nn
import timm

from ..attention import (
    BoTNetBlock,
    BoTNetBlockLinear,
    CABlock,
    ECABlock,
    CoordinateAttention,
    ECAttention
)


class EfficientNetV2_S_Vanilla(nn.Module):
    """EfficientNetV2-S baseline (khÃ´ng cÃ³ attention).
    
    ðŸ“Š ThÃ´ng sá»‘:
    - Params: ~21M
    - FLOPs: ~2.9G
    - Accuracy mong Ä‘á»£i: 92-93%
    - FPS (GPU T4): ~350
    - FPS (CPU): ~35
    
    âœ¨ Æ¯u Ä‘iá»ƒm:
    - Accuracy cao tá»« backbone máº¡nh
    - Training nhanh nhá» Progressive Learning
    - Fused-MBConv blocks tá»‘i Æ°u tá»‘c Ä‘á»™
    - Balanced giá»¯a accuracy vÃ  speed
    
    ðŸŽ¯ Khi nÃ o dÃ¹ng:
    - Cáº§n baseline máº¡nh Ä‘á»ƒ compare
    - Deploy production khÃ´ng cáº§n attention
    - Training nhanh vá»›i pretrained weights
    """
    def __init__(self, num_classes: int = 4, pretrained: bool = True, dropout: float = 0.2):
        super().__init__()
        
        # Load EfficientNetV2-S backbone
        self.backbone = timm.create_model(
            "tf_efficientnetv2_s",
            pretrained=pretrained,
            num_classes=0,  # KhÃ´ng dÃ¹ng classifier máº·c Ä‘á»‹nh
            drop_rate=0.0   # Dropout riÃªng á»Ÿ cuá»‘i
        )
        
        # Feature dimension tá»« backbone
        self.out_channels = self.backbone.num_features  # 1280 cho EfficientNetV2-S
        
        # Global pooling vÃ  classifier
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()
        self.fc = nn.Linear(self.out_channels, num_classes)
    
    def forward(self, x):
        # Extract features tá»« backbone
        x = self.backbone.forward_features(x)  # [B, 1280, H, W]
        
        # Global pooling vÃ  classify
        x = self.pool(x)  # [B, 1280, 1, 1]
        x = torch.flatten(x, 1)  # [B, 1280]
        x = self.dropout(x)
        x = self.fc(x)  # [B, num_classes]
        
        return x
    
    def get_classifier(self):
        """Tráº£ vá» classifier layer Ä‘á»ƒ tÃ­nh differential learning rates."""
        return self.fc


class EfficientNetV2_S_CA(nn.Module):
    """EfficientNetV2-S vá»›i Coordinate Attention.
    
    ðŸ“Š ThÃ´ng sá»‘:
    - Params: ~21.5M (+0.5M so vá»›i vanilla)
    - FLOPs: ~3.0G
    - Accuracy mong Ä‘á»£i: 93-95%
    - FPS (GPU T4): ~320
    
    âœ¨ Æ¯u Ä‘iá»ƒm:
    - CA giÃºp localize vá»‹ trÃ­ bá»‡nh trÃªn lÃ¡
    - Lightweight attention (chá»‰ +0.5M params)
    - Tá»‘t cho spatial information
    - Balance accuracy vs speed
    
    ðŸŽ¯ Khi nÃ o dÃ¹ng:
    - Bá»‡nh cÃ³ vá»‹ trÃ­ Ä‘áº·c trÆ°ng trÃªn lÃ¡
    - Cáº§n spatial localization
    - Æ¯u tiÃªn balance accuracy-speed
    """
    def __init__(self, num_classes: int = 4, reduction: int = 32, 
                 pretrained: bool = True, dropout: float = 0.2):
        super().__init__()
        
        self.backbone = timm.create_model(
            "tf_efficientnetv2_s",
            pretrained=pretrained,
            num_classes=0
        )
        
        self.out_channels = self.backbone.num_features  # 1280
        
        # Coordinate Attention block
        self.ca_block = CABlock(
            c_in=self.out_channels,
            c_out=self.out_channels,
            reduction=reduction
        )
        
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()
        self.fc = nn.Linear(self.out_channels, num_classes)
    
    def forward(self, x):
        x = self.backbone.forward_features(x)  # [B, 1280, H, W]
        x = self.ca_block(x)  # Coordinate Attention
        x = self.pool(x)
        x = torch.flatten(x, 1)
        x = self.dropout(x)
        return self.fc(x)
    
    def get_classifier(self):
        return self.fc


class EfficientNetV2_S_ECA(nn.Module):
    """EfficientNetV2-S vá»›i Efficient Channel Attention.
    
    ðŸ“Š ThÃ´ng sá»‘:
    - Params: ~21.01M (+0.01M - minimal!)
    - FLOPs: ~2.92G
    - Accuracy mong Ä‘á»£i: 92-94%
    - FPS (GPU T4): ~340 (gáº§n nhÆ° khÃ´ng giáº£m!)
    
    âœ¨ Æ¯u Ä‘iá»ƒm:
    - Cá»±c ká»³ lightweight (chá»‰ 1D conv)
    - Tá»‘c Ä‘á»™ gáº§n báº±ng vanilla
    - Channel-wise attention hiá»‡u quáº£
    - Best choice cho production
    
    ðŸŽ¯ Khi nÃ o dÃ¹ng:
    - Production deployment
    - Æ¯u tiÃªn tá»‘c Ä‘á»™ inference
    - Limited resources
    - Real-time applications
    """
    def __init__(self, num_classes: int = 4, k_size: int = 3,
                 pretrained: bool = True, dropout: float = 0.2):
        super().__init__()
        
        self.backbone = timm.create_model(
            "tf_efficientnetv2_s",
            pretrained=pretrained,
            num_classes=0
        )
        
        self.out_channels = self.backbone.num_features
        
        # ECA: cá»±c ká»³ lightweight
        self.eca_block = ECABlock(
            c_in=self.out_channels,
            c_out=self.out_channels,
            k_size=k_size
        )
        
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()
        self.fc = nn.Linear(self.out_channels, num_classes)
    
    def forward(self, x):
        x = self.backbone.forward_features(x)
        x = self.eca_block(x)  # ECA attention
        x = self.pool(x)
        x = torch.flatten(x, 1)
        x = self.dropout(x)
        return self.fc(x)
    
    def get_classifier(self):
        return self.fc


class EfficientNetV2_S_BoTLinear(nn.Module):
    """EfficientNetV2-S vá»›i BoTLinear (Linear Attention).
    
    ðŸ“Š ThÃ´ng sá»‘:
    - Params: ~23M (+2M)
    - FLOPs: ~3.5G
    - Accuracy mong Ä‘á»£i: 94-96%
    - FPS (GPU T4): ~280
    
    âœ¨ Æ¯u Ä‘iá»ƒm:
    - Global context via linear attention
    - Tá»‘t cho pattern recognition
    - O(n) complexity thay vÃ¬ O(nÂ²)
    - Accuracy cao
    
    ðŸŽ¯ Khi nÃ o dÃ¹ng:
    - Æ¯u tiÃªn accuracy
    - CÃ³ Ä‘á»§ GPU memory
    - Bá»‡nh cáº§n global context
    """
    def __init__(self, num_classes: int = 4, heads: int = 4,
                 pretrained: bool = True, dropout: float = 0.2):
        super().__init__()
        
        self.backbone = timm.create_model(
            "tf_efficientnetv2_s",
            pretrained=pretrained,
            num_classes=0
        )
        
        self.out_channels = self.backbone.num_features
        
        # BoTLinear block
        self.bot_block = BoTNetBlockLinear(
            c_in=self.out_channels,
            c_out=self.out_channels,
            heads=heads
        )
        
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()
        self.fc = nn.Linear(self.out_channels, num_classes)
    
    def forward(self, x):
        x = self.backbone.forward_features(x)
        x = self.bot_block(x)  # Linear Attention
        x = self.pool(x)
        x = torch.flatten(x, 1)
        x = self.dropout(x)
        return self.fc(x)
    
    def get_classifier(self):
        return self.fc


class EfficientNetV2_S_Hybrid(nn.Module):
    """EfficientNetV2-S Hybrid: CA + BoTLinear.
    
    ðŸ“Š ThÃ´ng sá»‘:
    - Params: ~24M (+3M)
    - FLOPs: ~3.8G
    - Accuracy mong Ä‘á»£i: 95-97% (CAO NHáº¤T!)
    - FPS (GPU T4): ~250
    
    âœ¨ Æ¯u Ä‘iá»ƒm:
    - Káº¿t há»£p spatial (CA) + global (BoTLinear)
    - Accuracy cao nháº¥t trong cÃ¡c variants
    - Há»c Ä‘Æ°á»£c multi-level features
    - Best cho competition
    
    ðŸŽ¯ Khi nÃ o dÃ¹ng:
    - Æ¯u tiÃªn accuracy tá»‘i Ä‘a
    - CÃ³ GPU máº¡nh (â‰¥8GB)
    - Competition/Research
    - BÃ i toÃ¡n khÃ³
    """
    def __init__(self, num_classes: int = 4, heads: int = 4, reduction: int = 32,
                 pretrained: bool = True, dropout: float = 0.2):
        super().__init__()
        
        self.backbone = timm.create_model(
            "tf_efficientnetv2_s",
            pretrained=pretrained,
            num_classes=0
        )
        
        self.out_channels = self.backbone.num_features
        
        # Hybrid: CA first (spatial), then BoTLinear (global)
        self.ca_block = CABlock(
            c_in=self.out_channels,
            c_out=self.out_channels,
            reduction=reduction
        )
        
        self.bot_block = BoTNetBlockLinear(
            c_in=self.out_channels,
            c_out=self.out_channels,
            heads=heads
        )
        
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()
        self.fc = nn.Linear(self.out_channels, num_classes)
    
    def forward(self, x):
        x = self.backbone.forward_features(x)  # [B, 1280, H, W]
        
        # Sequential: CA first for spatial, then BoTLinear for global
        x = self.ca_block(x)      # Coordinate Attention
        x = self.bot_block(x)     # Linear Attention
        
        x = self.pool(x)
        x = torch.flatten(x, 1)
        x = self.dropout(x)
        return self.fc(x)
    
    def get_classifier(self):
        return self.fc


# ============================================================================
# LIGHTWEIGHT VARIANT: EfficientNet-Lite0
# ============================================================================

class EfficientNet_Lite0_CA(nn.Module):
    """EfficientNet-Lite0 vá»›i Coordinate Attention.
    
    ðŸ“Š ThÃ´ng sá»‘:
    - Params: ~4.7M (NHáº¸ NHáº¤T!)
    - FLOPs: ~0.4G
    - Accuracy mong Ä‘á»£i: 90-92%
    - FPS (GPU T4): ~600+ 
    - FPS (CPU): ~80 (Ráº¤T NHANH!)
    
    âœ¨ Æ¯u Ä‘iá»ƒm:
    - Cá»±c ká»³ nháº¹ vÃ  nhanh
    - Optimized cho mobile/edge devices
    - KhÃ´ng cÃ³ SE blocks (giáº£m complexity)
    - Swish thay vÃ¬ hard-swish
    
    ðŸŽ¯ Khi nÃ o dÃ¹ng:
    - Mobile deployment
    - Edge devices (Raspberry Pi, Jetson Nano)
    - Real-time inference
    - Limited RAM/Storage
    - Battery-powered devices
    """
    def __init__(self, num_classes: int = 4, reduction: int = 16,
                 pretrained: bool = True, dropout: float = 0.2):
        super().__init__()
        
        # EfficientNet-Lite0: optimized cho mobile
        self.backbone = timm.create_model(
            "tf_efficientnet_lite0",
            pretrained=pretrained,
            num_classes=0
        )
        
        self.out_channels = self.backbone.num_features  # 1280
        
        # Lightweight CA vá»›i reduction nhá» hÆ¡n
        self.ca_block = CABlock(
            c_in=self.out_channels,
            c_out=self.out_channels,
            reduction=reduction
        )
        
        self.pool = nn.AdaptiveAvgPool2d(1)
        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()
        self.fc = nn.Linear(self.out_channels, num_classes)
    
    def forward(self, x):
        x = self.backbone.forward_features(x)
        x = self.ca_block(x)
        x = self.pool(x)
        x = torch.flatten(x, 1)
        x = self.dropout(x)
        return self.fc(x)
    
    def get_classifier(self):
        return self.fc
