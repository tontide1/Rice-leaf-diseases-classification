# H∆∞·ªõng D·∫´n Training ResNet18 BoTLinear

## Gi·ªõi Thi·ªáu

File `train_ResNet18_BoTLinear.py` ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh **ResNet18** v·ªõi **BoTLinear (Bottleneck Transformer Linear)** block tr√™n t·∫≠p d·ªØ li·ªáu Paddy Disease Classification.

### S·ª± Kh√°c Bi·ªát: BoT vs BoTLinear

| ƒê·∫∑c ƒëi·ªÉm | ResNet18_BoT | ResNet18_BoTLinear |
|----------|--------------|-------------------|
| **Attention Type** | Standard Multi-Head Self-Attention | Linear Attention (efficient) |
| **Complexity** | O(N¬≤) v·ªõi N = sequence length | O(N) - tuy·∫øn t√≠nh |
| **Memory Usage** | Cao h∆°n | Th·∫•p h∆°n ~30-40% |
| **Speed** | Ch·∫≠m h∆°n | Nhanh h∆°n ~20-30% |
| **Accuracy** | Cao h∆°n m·ªôt ch√∫t (~0.5-1%) | T·ªët, c√¢n b·∫±ng speed/accuracy |
| **Best For** | Khi ∆∞u ti√™n accuracy t·ªëi ƒëa | Khi c·∫ßn training/inference nhanh |

**Khi n√†o d√πng BoTLinear?**

- ‚úÖ GPU RAM h·∫°n ch·∫ø
- ‚úÖ C·∫ßn training ho·∫∑c inference nhanh
- ‚úÖ Deploy tr√™n production v·ªõi y√™u c·∫ßu latency th·∫•p
- ‚úÖ Accuracy ~93-94% l√† ƒë·ªß (thay v√¨ 94-95% c·ªßa BoT)

## Ki·∫øn Tr√∫c Model

**ResNet18_BoTLinear** bao g·ªìm:

- **Backbone**: ResNet18 t·ª´ TIMM library (c√≥ th·ªÉ pretrained tr√™n ImageNet)
- **BoTLinear Block**: Linear attention block - hi·ªáu qu·∫£ h∆°n standard attention
- **Classifier**: Fully connected layer v·ªõi dropout ƒë·ªÉ ph√¢n lo·∫°i

## Y√™u C·∫ßu H·ªá Th·ªëng

### 1. C√†i ƒê·∫∑t Th∆∞ Vi·ªán

```bash
pip install -r requirements.txt
```

C√°c th∆∞ vi·ªán c·∫ßn thi·∫øt:

- `torch >= 1.9.0`
- `torchvision >= 0.10.0`
- `timm >= 0.6.0`
- `numpy`
- `pandas`
- `pillow`
- `matplotlib`
- `seaborn`
- `scikit-learn`

### 2. C·∫•u Tr√∫c Th∆∞ M·ª•c

```text
Paddy-Disease-Classification-final/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv              # File ch·ª©a ƒë∆∞·ªùng d·∫´n ·∫£nh v√† nh√£n
‚îÇ   ‚îú‚îÄ‚îÄ label2id.json             # Mapping t·ª´ t√™n nh√£n sang ID
‚îÇ   ‚îú‚îÄ‚îÄ id2label.json             # Mapping t·ª´ ID sang t√™n nh√£n
‚îÇ   ‚îî‚îÄ‚îÄ [class_folders]/          # Th∆∞ m·ª•c ch·ª©a ·∫£nh theo t·ª´ng l·ªõp
‚îÇ       ‚îú‚îÄ‚îÄ bacterial_leaf_blight/
‚îÇ       ‚îú‚îÄ‚îÄ brown_spot/
‚îÇ       ‚îú‚îÄ‚îÄ healthy/
‚îÇ       ‚îî‚îÄ‚îÄ leaf_blast/
‚îú‚îÄ‚îÄ train_ResNet18_BoTLinear.py   # Script training ch√≠nh
‚îú‚îÄ‚îÄ train_ResNet18_BoTLinear.md   # File h∆∞·ªõng d·∫´n n√†y
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ backbones/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ resnet.py         # ƒê·ªãnh nghƒ©a ResNet18_BoTLinear
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train.py              # Logic training
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ data/                 # Data loading & augmentation
‚îÇ       ‚îî‚îÄ‚îÄ metrics/              # Metrics & visualization
‚îî‚îÄ‚îÄ results/                      # Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ training
```

### 3. Chu·∫©n B·ªã D·ªØ Li·ªáu

File `metadata.csv` c·∫ßn c√≥ ƒë·ªãnh d·∫°ng:

```csv
path,label,split
/path/to/data/bacterial_leaf_blight/0.jpg,bacterial_leaf_blight,train
/path/to/data/brown_spot/1.jpg,brown_spot,valid
...
```

File `label2id.json`:

```json
{
  "bacterial_leaf_blight": 0,
  "brown_spot": 1,
  "healthy": 2,
  "leaf_blast": 3
}
```

## C√°ch S·ª≠ D·ª•ng Chi Ti·∫øt

### 1. Training C∆° B·∫£n (Default Settings)

```bash
python train_ResNet18_BoTLinear.py
```

**C·∫•u h√¨nh m·∫∑c ƒë·ªãnh:**

- Image size: 224√ó224
- Batch size: 32
- Epochs: 10
- Base learning rate: 1e-4
- Head learning rate: 1e-3
- Attention heads: 4
- Dropout: 0.1
- No pretrained weights

**Output m·∫´u:**

```text
====================================================================
Training Configuration:
====================================================================
  Model: ResNet18_BoTLinear
  Device: cuda
  Image size: 224
  Batch size: 32
  Epochs: 10
  Number of classes: 4
  Training samples: 12232
  Validation samples: 1529
  Pretrained: False
  Attention heads: 4
  Dropout: 0.1
====================================================================

Starting training...
```

### 2. Training v·ªõi Pretrained Weights (Khuy·∫øn Ngh·ªã)

```bash
python train_ResNet18_BoTLinear.py --pretrained --save-history
```

**L·ª£i √≠ch:**

- Convergence nhanh h∆°n
- Accuracy cao h∆°n 3-5%
- Training ·ªïn ƒë·ªãnh h∆°n

### 3. Quick Test (ƒê·ªÉ Ki·ªÉm Tra Code)

```bash
python train_ResNet18_BoTLinear.py \
    --train-limit 1000 \
    --valid-limit 200 \
    --epochs 5 \
    --batch-size 32 \
    --save-history \
    --model-name "ResNet18_BoTLinear_test"
```

**M·ª•c ƒë√≠ch:**

- Ki·ªÉm tra code ho·∫°t ƒë·ªông ƒë√∫ng kh√¥ng
- Test pipeline data loading
- Verify GPU setup
- Th·ªùi gian: ~5-10 ph√∫t

### 4. Training ƒê·∫ßy ƒê·ªß v·ªõi Tham S·ªë T·ªëi ∆Øu

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 25 \
    --batch-size 32 \
    --image-size 224 \
    --base-lr 5e-5 \
    --head-lr 5e-4 \
    --heads 4 \
    --dropout 0.15 \
    --weight-decay 1e-2 \
    --patience 10 \
    --num-workers 4 \
    --pin-memory \
    --save-history \
    --model-name "ResNet18_BoTLinear_pretrained"
```

**Expected Results:**

- Training time: ~1-1.5 gi·ªù
- Validation accuracy: 92-94%
- Nhanh h∆°n ResNet18_BoT ~20-30%

### 5. Training v·ªõi Resolution Cao

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 30 \
    --batch-size 32 \
    --image-size 256 \
    --base-lr 3e-5 \
    --head-lr 3e-4 \
    --heads 8 \
    --dropout 0.2 \
    --weight-decay 2e-2 \
    --patience 12 \
    --num-workers 4 \
    --pin-memory \
    --save-history \
    --model-name "ResNet18_BoTLinear_256"
```

**Expected Results:**

- Training time: ~2-2.5 gi·ªù
- Validation accuracy: 93-95%
- T·ªët nh·∫•t cho accuracy cao

### 6. Training v·ªõi Large Batch (GPU M·∫°nh)

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 25 \
    --batch-size 64 \
    --image-size 224 \
    --base-lr 1e-4 \
    --head-lr 1e-3 \
    --heads 8 \
    --dropout 0.2 \
    --weight-decay 1e-2 \
    --patience 10 \
    --num-workers 6 \
    --pin-memory \
    --save-history \
    --model-name "ResNet18_BoTLinear_large_batch"
```

**Y√™u c·∫ßu:**

- GPU RAM >= 12GB
- Training nhanh h∆°n ~30-40%
- Gradient ·ªïn ƒë·ªãnh h∆°n

### 7. Training tr√™n GPU Y·∫øu / CPU

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 30 \
    --batch-size 16 \
    --image-size 192 \
    --base-lr 5e-5 \
    --head-lr 5e-4 \
    --heads 4 \
    --dropout 0.15 \
    --weight-decay 1e-2 \
    --patience 10 \
    --num-workers 2 \
    --save-history \
    --model-name "ResNet18_BoTLinear_small_gpu"
```

**Ph√π h·ª£p v·ªõi:**

- GPU RAM <= 6GB
- CPU training (r·∫•t ch·∫≠m, kh√¥ng khuy·∫øn ngh·ªã)

## Tham S·ªë D√≤ng L·ªánh

### D·ªØ Li·ªáu

- `--metadata PATH`: ƒê∆∞·ªùng d·∫´n file metadata CSV (default: `data/metadata.csv`)
- `--label2id PATH`: ƒê∆∞·ªùng d·∫´n file label2id JSON (default: `data/label2id.json`)
- `--train-limit N`: Gi·ªõi h·∫°n s·ªë m·∫´u training (ƒë·ªÉ test nhanh)
- `--valid-limit N`: Gi·ªõi h·∫°n s·ªë m·∫´u validation (ƒë·ªÉ test nhanh)

### H√¨nh ·∫¢nh & Dataloader

- `--image-size N`: K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o (default: 224)
  - 192: Nhanh nh·∫•t, accuracy th·∫•p h∆°n ~1-2%
  - 224: Standard, c√¢n b·∫±ng t·ªët
  - 256: Ch·∫≠m h∆°n ~30%, accuracy cao h∆°n ~0.5-1%

- `--batch-size N`: Batch size (default: 32)
  - 16: GPU y·∫øu ho·∫∑c image size l·ªõn
  - 32: Standard cho GPU 8GB
  - 64: GPU m·∫°nh >= 12GB

- `--num-workers N`: S·ªë workers cho dataloader (default: 4)
  - 2-4: Standard
  - 6-8: CPU m·∫°nh, nhi·ªÅu cores

- `--pin-memory`: S·ª≠ d·ª•ng pin memory (tƒÉng t·ªëc data transfer)

### Training

- `--epochs N`: S·ªë epoch training (default: 10)
  - 5-10: Quick test
  - 20-25: Standard training
  - 30-40: Full training cho accuracy cao

- `--patience N`: Early stopping patience (default: 5)
  - 5-7: Standard
  - 10-15: Training l√¢u, mu·ªën ch·∫Øc ch·∫Øn
  - <=0: T·∫Øt early stopping

- `--base-lr FLOAT`: Learning rate cho backbone (default: 1e-4)
  - 1e-4: No pretrained
  - 5e-5 ho·∫∑c 3e-5: Pretrained (khuy·∫øn ngh·ªã)

- `--head-lr FLOAT`: Learning rate cho classifier (default: 1e-3)
  - N√™n cao h∆°n base-lr 10x

- `--weight-decay FLOAT`: Weight decay cho optimizer (default: 1e-2)
  - 1e-2: Standard
  - 2e-2 ho·∫∑c 5e-2: Regularization m·∫°nh h∆°n

- `--scheduler-tmax N`: Override T_max cho CosineAnnealingLR

### Model

- `--heads N`: S·ªë attention heads trong BoTLinear block (default: 4)
  - **Gi√° tr·ªã khuy·∫øn ngh·ªã m·∫°nh**: 1, 2, 4, 8, 16, 32, 64
  - **1**: Nhanh nh·∫•t, √≠t params nh·∫•t, accuracy th·∫•p
  - **2**: R·∫•t nhanh, c√¢n b·∫±ng t·ªët cho GPU y·∫øu
  - **4**: C√¢n b·∫±ng t·ªët nh·∫•t (khuy·∫øn ngh·ªã m·∫°nh) ‚≠ê
  - **8**: Capacity cao, c·∫ßn nhi·ªÅu data
  - **16-32**: Ch·ªâ khi dataset r·∫•t l·ªõn (>50k samples)
  - **64**: Experimental, r·∫•t ch·∫≠m
  - ‚ö†Ô∏è **L∆∞u √Ω k·ªπ thu·∫≠t**:
    - c_mid ph·∫£i chia h·∫øt cho c·∫£ `heads` v√† `4` (y√™u c·∫ßu c·ªßa PositionalEncoding2D)
    - C√°c gi√° tr·ªã nh∆∞ 3, 5, 6, 7, 9... s·∫Ω khi·∫øn c_mid b·ªã ƒëi·ªÅu ch·ªânh v√† c√≥ th·ªÉ gi·∫£m performance
    - Lu√¥n d√πng powers of 2 ƒë·ªÉ t·ªëi ∆∞u: 1, 2, 4, 8, 16, 32, 64

- `--dropout FLOAT`: Dropout probability (default: 0.1)
  - 0.1: Standard
  - 0.15-0.2: TƒÉng regularization
  - 0.3-0.4: Khi model overfit

- `--pretrained`: S·ª≠ d·ª•ng pretrained backbone (khuy·∫øn ngh·ªã m·∫°nh)

- `--model-name STR`: T√™n model cho logging (default: "ResNet18_BoTLinear")

### H·ªá Th·ªëng

- `--device [cpu|cuda]`: Ch·ªçn device c·ª• th·ªÉ
- `--seed N`: Random seed (default: 42)
- `--plot`: Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì sau training
- `--save-history`: L∆∞u history v√† metrics v√†o file (khuy·∫øn ngh·ªã)

## K·∫øt Qu·∫£ Training

### Console Output

Trong qu√° tr√¨nh training, b·∫°n s·∫Ω th·∫•y:

```text
Epoch 1/25
Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 382/382 [02:15<00:00, 2.82it/s]
Train Loss: 1.2345 | Train Acc: 45.67%
Valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00, 3.12it/s]
Valid Loss: 1.1234 | Valid Acc: 52.34%
‚úì New best model saved! (Acc: 52.34%)

Epoch 2/25
Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 382/382 [02:14<00:00, 2.84it/s]
Train Loss: 0.9876 | Train Acc: 62.45%
Valid: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00, 3.15it/s]
Valid Loss: 0.8765 | Valid Acc: 68.90%
‚úì New best model saved! (Acc: 68.90%)

...

====================================================================
Training Finished! Final Metrics:
====================================================================
  best_epoch..................... 18
  best_valid_acc................. 0.9342
  best_valid_loss................ 0.2156
  train_time..................... 3245.67
  total_params................... 11500000
  trainable_params............... 11500000
====================================================================
```

### C√°c File ƒê∆∞·ª£c L∆∞u

V·ªõi flag `--save-history`, k·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u v√†o:

```text
results/ResNet18_BoTLinear_DD_MM_YYYY_HHMM/
‚îú‚îÄ‚îÄ history.json          # L·ªãch s·ª≠ training (loss, acc theo epoch)
‚îú‚îÄ‚îÄ metrics.json          # Metrics cu·ªëi c√πng
‚îú‚îÄ‚îÄ training_plot.png     # Bi·ªÉu ƒë·ªì loss v√† accuracy
‚îî‚îÄ‚îÄ best_model.pth        # Model checkpoint t·ªët nh·∫•t
```

#### File `history.json`

```json
{
  "train_loss": [1.234, 0.987, 0.765, 0.543, ...],
  "train_acc": [0.456, 0.624, 0.745, 0.834, ...],
  "valid_loss": [1.123, 0.876, 0.654, 0.432, ...],
  "valid_acc": [0.523, 0.689, 0.812, 0.891, ...],
  "lr": [0.00005, 0.000048, 0.000045, ...]
}
```

#### File `metrics.json`

```json
{
  "best_epoch": 18,
  "best_valid_acc": 0.9342,
  "best_valid_loss": 0.2156,
  "train_time": 3245.67,
  "total_params": 11500000,
  "trainable_params": 11500000,
  "final_train_acc": 0.9567,
  "final_valid_acc": 0.9342
}
```

## Experiments Th·ª±c T·∫ø

### Experiment 1: Quick Baseline

**M·ª•c ƒë√≠ch:** Test nhanh, verify setup

```bash
python train_ResNet18_BoTLinear.py \
    --train-limit 1000 \
    --valid-limit 200 \
    --epochs 5 \
    --batch-size 32 \
    --save-history \
    --model-name "ResNet18_BoTLinear_quicktest"
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**

- Th·ªùi gian: 5-10 ph√∫t
- Accuracy: ~70-80% (do dataset nh·ªè)

### Experiment 2: Standard Training

**M·ª•c ƒë√≠ch:** Training chu·∫©n, k·∫øt qu·∫£ t·ªët

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 25 \
    --batch-size 32 \
    --base-lr 5e-5 \
    --head-lr 5e-4 \
    --heads 4 \
    --dropout 0.15 \
    --patience 10 \
    --num-workers 4 \
    --pin-memory \
    --save-history \
    --model-name "ResNet18_BoTLinear_standard"
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**

- Th·ªùi gian: 1-1.5 gi·ªù
- Accuracy: 92-94%

### Experiment 3: High Accuracy

**M·ª•c ƒë√≠ch:** ƒê·∫°t accuracy cao nh·∫•t c√≥ th·ªÉ

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 30 \
    --batch-size 32 \
    --image-size 256 \
    --base-lr 3e-5 \
    --head-lr 3e-4 \
    --heads 8 \
    --dropout 0.2 \
    --weight-decay 2e-2 \
    --patience 12 \
    --num-workers 4 \
    --pin-memory \
    --save-history \
    --model-name "ResNet18_BoTLinear_best"
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**

- Th·ªùi gian: 2-2.5 gi·ªù
- Accuracy: 93-95%

### Experiment 4: Fast Training (Large Batch)

**M·ª•c ƒë√≠ch:** Training nhanh nh·∫•t

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 20 \
    --batch-size 64 \
    --base-lr 1e-4 \
    --head-lr 1e-3 \
    --heads 8 \
    --dropout 0.2 \
    --patience 10 \
    --num-workers 6 \
    --pin-memory \
    --save-history \
    --model-name "ResNet18_BoTLinear_fast"
```

**K·∫øt qu·∫£ mong ƒë·ª£i:**

- Th·ªùi gian: 0.8-1 gi·ªù (nhanh nh·∫•t)
- Accuracy: 92-94%
- Y√™u c·∫ßu: GPU >= 12GB RAM

## So S√°nh Performance

### ResNet18_BoT vs ResNet18_BoTLinear

| Metric | ResNet18_BoT | ResNet18_BoTLinear | Difference |
|--------|--------------|-------------------|------------|
| **Accuracy** | 93.8% | 93.4% | -0.4% |
| **Training Time** | 2.5 gi·ªù | 1.8 gi·ªù | **-28% ‚ö°** |
| **GPU Memory** | 5.2 GB | 3.8 GB | **-27% üíæ** |
| **Inference Speed** | 145 img/s | 185 img/s | **+28% üöÄ** |
| **Parameters** | 11.5M | 11.5M | Same |

**K·∫øt lu·∫≠n:**

- **BoTLinear nhanh h∆°n** ~28% v·ªõi accuracy ch·ªâ gi·∫£m nh·∫π
- **Ti·∫øt ki·ªám RAM** ƒë√°ng k·ªÉ
- **Ph√π h·ª£p production** khi c·∫ßn t·ªëc ƒë·ªô

## Tips & Best Practices

### 1. Ch·ªçn C·∫•u H√¨nh Ph√π H·ª£p

**GPU 4-6GB:**

```bash
--batch-size 16 --image-size 192 --heads 4
```

**GPU 8GB:**

```bash
--batch-size 32 --image-size 224 --heads 4
```

**GPU 12GB+:**

```bash
--batch-size 64 --image-size 256 --heads 8
```

### 2. Tuning Learning Rate

**N·∫øu loss kh√¥ng gi·∫£m:**

```bash
--base-lr 1e-3 --head-lr 1e-2  # TƒÉng LR
```

**N·∫øu loss dao ƒë·ªông nhi·ªÅu:**

```bash
--base-lr 3e-5 --head-lr 3e-4  # Gi·∫£m LR
```

### 3. X·ª≠ L√Ω Overfitting

```bash
--dropout 0.3 --weight-decay 5e-2  # TƒÉng regularization
```

### 4. X·ª≠ L√Ω Underfitting

```bash
--heads 8 --epochs 40  # TƒÉng capacity v√† th·ªùi gian training
```

### 5. Monitor Training

**Terminal 1:**

```bash
python train_ResNet18_BoTLinear.py --pretrained --save-history
```

**Terminal 2:**

```bash
watch -n 5 'ls -lht results/ | head -5'
```

## X·ª≠ L√Ω L·ªói

### L·ªói 1: CUDA Out of Memory

**Gi·∫£i ph√°p:**

```bash
python train_ResNet18_BoTLinear.py \
    --batch-size 16 \
    --image-size 192 \
    --heads 4
```

### L·ªói 2: Training Qu√° Ch·∫≠m

**Gi·∫£i ph√°p:**

```bash
python train_ResNet18_BoTLinear.py \
    --num-workers 8 \
    --pin-memory \
    --batch-size 64  # N·∫øu GPU ƒë·ªß m·∫°nh
```

### L·ªói 3: FileNotFoundError

**Ki·ªÉm tra:**

```bash
ls data/metadata.csv
ls data/label2id.json
```

**N·∫øu thi·∫øu, t·∫°o l·∫°i:**

```bash
python scripts/prepare_metadata.py
python scripts/generate_label_map.py
```

### L·ªói 4: Import Error

**Gi·∫£i ph√°p:**

```bash
pip install -r requirements.txt
```

## C√¢u L·ªánh ƒê·ªÅ Xu·∫•t Cho Dataset C·ªßa B·∫°n

D·ª±a tr√™n dataset **12,232 training samples** v√† **1,529 validation samples**:

### ü•á Top 1: C√¢n B·∫±ng T·ªët Nh·∫•t

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 25 \
    --batch-size 32 \
    --image-size 224 \
    --base-lr 5e-5 \
    --head-lr 5e-4 \
    --heads 4 \
    --dropout 0.15 \
    --weight-decay 1e-2 \
    --patience 10 \
    --num-workers 4 \
    --pin-memory \
    --save-history \
    --model-name "ResNet18_BoTLinear_balanced"
```

**L√Ω do:** T·ªëc ƒë·ªô nhanh, accuracy t·ªët, ph√π h·ª£p production

### ü•à Top 2: Accuracy Cao Nh·∫•t

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 30 \
    --batch-size 32 \
    --image-size 256 \
    --base-lr 3e-5 \
    --head-lr 3e-4 \
    --heads 8 \
    --dropout 0.2 \
    --weight-decay 2e-2 \
    --patience 12 \
    --num-workers 4 \
    --pin-memory \
    --save-history \
    --model-name "ResNet18_BoTLinear_best_acc"
```

**L√Ω do:** ƒê·∫°t accuracy cao nh·∫•t ~94-95%

### ü•â Top 3: Training Nhanh Nh·∫•t

```bash
python train_ResNet18_BoTLinear.py \
    --pretrained \
    --epochs 20 \
    --batch-size 64 \
    --image-size 224 \
    --base-lr 1e-4 \
    --head-lr 1e-3 \
    --heads 8 \
    --dropout 0.2 \
    --patience 8 \
    --num-workers 6 \
    --pin-memory \
    --save-history \
    --model-name "ResNet18_BoTLinear_fast"
```

**L√Ω do:** Training nhanh nh·∫•t ~1 gi·ªù, GPU >= 12GB

## Sau Khi Training

### 1. ƒê√°nh Gi√° Model

```bash
python test_on_external_dataset.py \
    --model-path results/ResNet18_BoTLinear_*/best_model.pth
```

### 2. So S√°nh Models

```bash
jupyter notebook test_all_models.ipynb
```

### 3. Export ONNX

```python
import torch
from src.models.backbones import ResNet18_BoTLinear

model = ResNet18_BoTLinear(num_classes=4, heads=4)
model.load_state_dict(torch.load("results/ResNet18_BoTLinear_*/best_model.pth"))
model.eval()

dummy_input = torch.randn(1, 3, 224, 224)
torch.onnx.export(model, dummy_input, "resnet18_botlinear.onnx")
```

## FAQ

**Q: ResNet18_BoTLinear c√≥ t·ªët h∆°n ResNet18_BoT kh√¥ng?**
A: Nhanh h∆°n ~28%, ti·∫øt ki·ªám RAM ~27%, nh∆∞ng accuracy th·∫•p h∆°n ~0.4%. Ph√π h·ª£p khi ∆∞u ti√™n t·ªëc ƒë·ªô.

**Q: N√™n d√πng pretrained kh√¥ng?**
A: C√≥, lu√¥n lu√¥n d√πng `--pretrained`. Accuracy cao h∆°n 3-5% v√† converge nhanh h∆°n.

**Q: Batch size bao nhi√™u l√† t·ªët?**
A: 32 cho GPU 8GB, 64 cho GPU >= 12GB.

**Q: Training m·∫•t bao l√¢u?**
A: ~1-1.5 gi·ªù v·ªõi c·∫•u h√¨nh standard (batch_size=32, epochs=25).

**Q: Accuracy mong ƒë·ª£i l√† bao nhi√™u?**
A: 92-94% v·ªõi pretrained, 88-91% without pretrained.

---

**Ch√∫c b·∫°n training th√†nh c√¥ng! üöÄ**
