# HÆ°á»›ng dáº«n Train ResNet18_Hybrid

## ğŸ“‹ Tá»•ng quan

**ResNet18_Hybrid** lÃ  kiáº¿n trÃºc káº¿t há»£p giá»¯a **BoTLinear** (Linear Attention) vÃ  **Coordinate Attention** (CA), mang láº¡i accuracy cao nháº¥t trong cÃ¡c biáº¿n thá»ƒ ResNet18.

### ğŸ¯ Äáº·c Ä‘iá»ƒm chÃ­nh

- **Accuracy mong Ä‘á»£i**: 94-96% (CAO NHáº¤T!)
- **Tá»‘c Ä‘á»™**: Trung bÃ¬nh (cháº­m hÆ¡n BoT ~10%)
- **Params**: Cao nháº¥t (+30% so vá»›i base ResNet18)

### âœ¨ Æ¯u Ä‘iá»ƒm

- âœ… Káº¿t há»£p Ä‘iá»ƒm máº¡nh cá»§a cáº£ BoTLinear vÃ  Coordinate Attention
- âœ… **BoTLinear**: Capture global context qua linear attention
- âœ… **CA**: Localization tá»‘t qua coordinate attention (height + width)
- âœ… Há»c Ä‘Æ°á»£c cáº£ global features vÃ  local spatial features
- âœ… PhÃ¹ há»£p cho bÃ i toÃ¡n phá»©c táº¡p cáº§n accuracy cao

### ğŸ¯ Khi nÃ o nÃªn dÃ¹ng

- âœ… Æ¯u tiÃªn **accuracy cao nháº¥t**
- âœ… CÃ³ Ä‘á»§ **computational resources** (GPU memory â‰¥ 8GB)
- âœ… BÃ i toÃ¡n khÃ³, cáº§n model máº¡nh
- âœ… Research hoáº·c Competition

---

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Training cÆ¡ báº£n (Pretrained backbone)

```bash
python train_ResNet18_Hybrid.py \
    --pretrained \
    --epochs 10 \
    --batch-size 32 \
    --save-history
```

**Giáº£i thÃ­ch cÃ¡c tham sá»‘:**

- `--pretrained`: Sá»­ dá»¥ng backbone pretrained tá»« ImageNet (khuyáº¿n nghá»‹)
- `--epochs 10`: Train 10 epochs
- `--batch-size 32`: Batch size 32 (giáº£m xuá»‘ng náº¿u thiáº¿u GPU memory)
- `--save-history`: LÆ°u history vÃ  metrics vÃ o thÆ° má»¥c `results/`

---

### 2. Training vá»›i cáº¥u hÃ¬nh tÃ¹y chá»‰nh

```bash
python train_ResNet18_Hybrid.py \
    --pretrained \
    --epochs 20 \
    --batch-size 16 \
    --image-size 224 \
    --base-lr 5e-5 \
    --head-lr 5e-4 \
    --weight-decay 1e-2 \
    --heads 4 \
    --reduction 32 \
    --dropout 0.2 \
    --patience 7 \
    --num-workers 8 \
    --pin-memory \
    --save-history \
    --plot
```

**Giáº£i thÃ­ch cÃ¡c tham sá»‘ nÃ¢ng cao:**

- `--image-size 224`: KÃ­ch thÆ°á»›c áº£nh input (224x224)
- `--base-lr 5e-5`: Learning rate cho backbone (tháº¥p hÆ¡n vÃ¬ pretrained)
- `--head-lr 5e-4`: Learning rate cho classifier head (cao hÆ¡n)
- `--weight-decay 1e-2`: Weight decay cho regularization
- `--heads 4`: Sá»‘ attention heads trong BoTLinear block
- `--reduction 32`: Reduction ratio cho Coordinate Attention
- `--dropout 0.2`: Dropout probability (0.2 = 20%)
- `--patience 7`: Early stopping sau 7 epochs khÃ´ng cáº£i thiá»‡n
- `--num-workers 8`: Sá»‘ worker threads cho DataLoader
- `--pin-memory`: Pin memory cho tá»‘c Ä‘á»™ transfer nhanh hÆ¡n
- `--plot`: Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ training sau khi hoÃ n thÃ nh

---

### 3. Quick test (Train nhanh vá»›i dá»¯ liá»‡u giá»›i háº¡n)

```bash
python train_ResNet18_Hybrid.py \
    --pretrained \
    --epochs 3 \
    --batch-size 16 \
    --train-limit 500 \
    --valid-limit 200 \
    --save-history
```

**Giáº£i thÃ­ch:**

- `--train-limit 500`: Chá»‰ dÃ¹ng 500 máº«u training (Ä‘á»ƒ test nhanh)
- `--valid-limit 200`: Chá»‰ dÃ¹ng 200 máº«u validation

---

### 4. Training tá»« scratch (KhÃ´ng dÃ¹ng pretrained)

```bash
python train_ResNet18_Hybrid.py \
    --epochs 30 \
    --batch-size 32 \
    --base-lr 1e-3 \
    --head-lr 1e-3 \
    --save-history
```

**LÆ°u Ã½:** Training tá»« scratch cáº§n nhiá»u epochs hÆ¡n vÃ  learning rate cao hÆ¡n.

---

## ğŸ“Š CÃ¡c tham sá»‘ quan trá»ng

### Tham sá»‘ Model

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ | Khuyáº¿n nghá»‹ |
|---------|----------|-------|-------------|
| `--heads` | 4 | Sá»‘ attention heads trong BoTLinear | 4-8 |
| `--reduction` | 32 | Reduction ratio cho CA | 16-32 |
| `--dropout` | 0.1 | Dropout probability | 0.1-0.3 |
| `--pretrained` | False | DÃ¹ng pretrained weights | **LuÃ´n báº­t** |

### Tham sá»‘ Training

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ | Khuyáº¿n nghá»‹ |
|---------|----------|-------|-------------|
| `--epochs` | 10 | Sá»‘ epochs training | 10-20 |
| `--batch-size` | 32 | Batch size | 16-64 |
| `--patience` | 5 | Early stopping patience | 5-10 |
| `--base-lr` | 1e-4 | Learning rate backbone | 5e-5 (pretrained) |
| `--head-lr` | 1e-3 | Learning rate head | 5e-4 - 1e-3 |

### Tham sá»‘ Dá»¯ liá»‡u

| Tham sá»‘ | Máº·c Ä‘á»‹nh | MÃ´ táº£ |
|---------|----------|-------|
| `--metadata` | data/metadata.csv | ÄÆ°á»ng dáº«n metadata |
| `--label2id` | data/label2id.json | ÄÆ°á»ng dáº«n label mapping |
| `--image-size` | 224 | KÃ­ch thÆ°á»›c áº£nh |
| `--num-workers` | 4 | Sá»‘ workers DataLoader |

---

## ğŸ’¡ Tips & Best Practices

### 1. GPU Memory Management

```bash
# Náº¿u gáº·p lá»—i Out of Memory (OOM), giáº£m batch size:
python train_ResNet18_Hybrid.py --batch-size 16  # hoáº·c 8
```

### 2. Optimal Hyperparameters (Tá»« experiments)

```bash
python train_ResNet18_Hybrid.py \
    --pretrained \
    --epochs 15 \
    --batch-size 32 \
    --base-lr 5e-5 \
    --head-lr 5e-4 \
    --heads 4 \
    --reduction 32 \
    --dropout 0.15 \
    --patience 7 \
    --save-history
```

### 3. Training trÃªn CPU (khÃ´ng khuyáº¿n nghá»‹)

```bash
python train_ResNet18_Hybrid.py \
    --device cpu \
    --batch-size 8 \
    --epochs 5
```

### 4. Resume tá»« checkpoint

Hiá»‡n táº¡i chÆ°a support resume. Äá»ƒ resume training, cáº§n thÃªm code load checkpoint.

---

## ğŸ“ Output Structure

Sau khi training vá»›i `--save-history`, káº¿t quáº£ Ä‘Æ°á»£c lÆ°u vÃ o:

```
results/
â””â”€â”€ ResNet18_Hybrid_DD_MM_YYYY_HHMM/
    â”œâ”€â”€ history.json           # Training history (loss, acc theo epoch)
    â”œâ”€â”€ metrics.json          # Final metrics (best acc, loss, etc.)
    â”œâ”€â”€ training_plot.png     # Biá»ƒu Ä‘á»“ training curves
    â””â”€â”€ best_model.pt         # Best model checkpoint (náº¿u cÃ³ save)
```

### VÃ­ dá»¥ metrics.json

```json
{
  "valid_acc": 0.9542,
  "valid_loss": 0.1234,
  "train_acc": 0.9821,
  "train_loss": 0.0567,
  "best_epoch": 12
}
```

---

## ğŸ” So sÃ¡nh vá»›i cÃ¡c variants khÃ¡c

| Model | Accuracy | Speed | Memory | Use Case |
|-------|----------|-------|---------|----------|
| **ResNet18_Hybrid** | 94-96% â­ | Trung bÃ¬nh | Cao | **Accuracy tá»‘i Ä‘a** |
| ResNet18_BoT | 93-95% | Trung bÃ¬nh | Trung bÃ¬nh | Balanced |
| ResNet18_BoTLinear | 92-94% | Nhanh | Trung bÃ¬nh | Production |
| ResNet18_CA | 92-94% | Nhanh | Tháº¥p | Edge devices |
| ResNet18_ECA | 91-93% | Ráº¥t nhanh | Ráº¥t tháº¥p | Mobile/Edge |

### ğŸ’¡ Khuyáº¿n nghá»‹ lá»±a chá»n

- **ResNet18_Hybrid**: Khi muá»‘n accuracy cao nháº¥t, cÃ³ Ä‘á»§ GPU
- **ResNet18_BoTLinear**: Balance tá»‘t giá»¯a accuracy vÃ  speed
- **ResNet18_CA**: Deploy trÃªn edge devices vá»›i RAM háº¡n cháº¿
- **ResNet18_ECA**: Mobile/Real-time applications

---

## âš ï¸ Troubleshooting

### 1. Out of Memory (OOM)

```bash
# Giáº£m batch size
python train_ResNet18_Hybrid.py --batch-size 8

# Hoáº·c giáº£m image size
python train_ResNet18_Hybrid.py --image-size 192 --batch-size 16
```

### 2. Training quÃ¡ cháº­m

```bash
# TÄƒng num_workers vÃ  báº­t pin_memory
python train_ResNet18_Hybrid.py --num-workers 8 --pin-memory
```

### 3. Overfitting

```bash
# TÄƒng dropout vÃ  weight decay
python train_ResNet18_Hybrid.py --dropout 0.3 --weight-decay 5e-2
```

### 4. Underfitting

```bash
# Giáº£m dropout, tÄƒng epochs, tÄƒng learning rate
python train_ResNet18_Hybrid.py --dropout 0.05 --epochs 30 --head-lr 1e-3
```

---

## ğŸ“š Chi tiáº¿t kiáº¿n trÃºc

### ResNet18_Hybrid Architecture

```
Input (3, 224, 224)
    â†“
Stem (Conv + BN + ReLU + MaxPool)
    â†“
Layer1 (64 channels)
    â†“
Layer2 (128 channels)
    â†“
Layer3 (256 channels)
    â†“
Layer4 (512 channels)
    â†“
Coordinate Attention Block  â† Spatial localization
    â†“
BoTLinear Block            â† Global context
    â†“
Global Average Pooling
    â†“
Dropout
    â†“
Linear Classifier (num_classes)
    â†“
Output (logits)
```

### Sequential Order

1. **CA Block trÆ°á»›c**: Capture spatial information (height, width)
2. **BoTLinear sau**: Model global dependencies

Thá»© tá»± nÃ y Ä‘Æ°á»£c chá»n vÃ¬ á»•n Ä‘á»‹nh hÆ¡n trong quÃ¡ trÃ¬nh training.

---

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á», kiá»ƒm tra:

1. âœ… GPU cÃ³ Ä‘á»§ memory khÃ´ng? (`nvidia-smi`)
2. âœ… Dependencies Ä‘Ã£ cÃ i Ä‘á»§ chÆ°a? (`pip install -r requirements.txt`)
3. âœ… ÄÆ°á»ng dáº«n data Ä‘Ãºng khÃ´ng?
4. âœ… CUDA compatible vá»›i PyTorch version khÃ´ng?

---

## ğŸ“ References

- **BoT (Bottleneck Transformers)**: [Paper](https://arxiv.org/abs/2101.11605)
- **Coordinate Attention**: [Paper](https://arxiv.org/abs/2103.02907)
- **ResNet**: [Paper](https://arxiv.org/abs/1512.03385)

---

**ChÃºc báº¡n training thÃ nh cÃ´ng! ğŸš€**
