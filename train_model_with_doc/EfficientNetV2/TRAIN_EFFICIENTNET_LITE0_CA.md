# üöÄ H∆∞·ªõng D·∫´n Training EfficientNet-Lite0 + CA

## üìã M·ª•c L·ª•c

1. [Gi·ªõi Thi·ªáu Model](#gi·ªõi-thi·ªáu-model)
2. [Y√™u C·∫ßu H·ªá Th·ªëng](#y√™u-c·∫ßu-h·ªá-th·ªëng)
3. [C√†i ƒê·∫∑t](#c√†i-ƒë·∫∑t)
4. [Chu·∫©n B·ªã D·ªØ Li·ªáu](#chu·∫©n-b·ªã-d·ªØ-li·ªáu)
5. [Training](#training)
6. [C√°c Tham S·ªë Quan Tr·ªçng](#c√°c-tham-s·ªë-quan-tr·ªçng)
7. [K·∫øt Qu·∫£ Mong ƒê·ª£i](#k·∫øt-qu·∫£-mong-ƒë·ª£i)
8. [Troubleshooting](#troubleshooting)
9. [Tips & Tricks](#tips--tricks)

---

## üéØ Gi·ªõi Thi·ªáu Model

**EfficientNet-Lite0 + Coordinate Attention** l√† model c·ª±c k·ª≥ nh·∫π ƒë∆∞·ª£c t·ªëi ∆∞u cho **mobile v√† edge devices**.

### ƒê·∫∑c ƒêi·ªÉm N·ªïi B·∫≠t

| ƒê·∫∑c ƒëi·ªÉm | Gi√° tr·ªã |
|----------|---------|
| **S·ªë parameters** | ~4.7M (nh·∫π nh·∫•t!) |
| **FLOPs** | ~0.4G |
| **Accuracy mong ƒë·ª£i** | 90-92% |
| **FPS (GPU T4)** | 600+ |
| **FPS (CPU)** | ~80 |
| **Model size** | ~19 MB |

### So S√°nh V·ªõi C√°c Model Kh√°c

| Model | Params | FLOPs | Accuracy | FPS (GPU) | FPS (CPU) |
|-------|--------|-------|----------|-----------|-----------|
| EfficientNet-Lite0 + CA | 4.7M | 0.4G | 90-92% | 600+ | 80 |
| MobileNetV3-Small + BoT | 3.5M | 0.3G | 91-93% | 550 | 70 |
| ResNet18 + BoT | 11M | 1.8G | 93-95% | 400 | 45 |
| EfficientNetV2-S + CA | 21.5M | 3.0G | 93-95% | 320 | 25 |

### Khi N√†o N√™n D√πng Model N√†y?

‚úÖ **N√™n d√πng khi:**

- Deploy tr√™n **mobile devices** (Android/iOS)
- Ch·∫°y tr√™n **edge devices** (Raspberry Pi, Jetson Nano)
- C·∫ßn **real-time inference** v·ªõi ƒë·ªô tr·ªÖ th·∫•p
- Gi·ªõi h·∫°n **RAM/Storage** (< 50MB model size)
- Thi·∫øt b·ªã ch·∫°y **pin** (battery-powered)
- CPU inference l√† ch√≠nh

‚ùå **Kh√¥ng n√™n d√πng khi:**

- C·∫ßn accuracy tuy·ªát ƒë·ªëi cao nh·∫•t (>95%)
- C√≥ GPU server m·∫°nh v√† kh√¥ng quan t√¢m t·ªëc ƒë·ªô
- Dataset c√≥ nhi·ªÖu ph·ª©c t·∫°p ho·∫∑c c·∫ßn multi-scale features

---

## üíª Y√™u C·∫ßu H·ªá Th·ªëng

### T·ªëi Thi·ªÉu (CPU)

- **CPU:** 4 cores
- **RAM:** 8GB
- **Storage:** 2GB (d·ªØ li·ªáu + model)
- **OS:** Linux/Windows/macOS

### Khuy·∫øn Ngh·ªã (GPU)

- **GPU:** NVIDIA GPU v·ªõi >= 4GB VRAM (GTX 1650 tr·ªü l√™n)
- **RAM:** 16GB
- **Storage:** SSD v·ªõi >= 10GB
- **CUDA:** >= 11.0

### Software

- **Python:** >= 3.8
- **PyTorch:** >= 1.10
- **timm:** >= 0.6.0
- **CUDA Toolkit:** 11.0+ (n·∫øu d√πng GPU)

---

## üîß C√†i ƒê·∫∑t

### 1. Clone Repository

```bash
git clone https://github.com/tontide1/Rice-leaf-diseases-classification.git
cd Rice-leaf-diseases-classification
```

### 2. T·∫°o Virtual Environment

```bash
# D√πng venv
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ho·∫∑c
venv\Scripts\activate  # Windows

# Ho·∫∑c d√πng conda
conda create -n paddy python=3.10
conda activate paddy
```

### 3. C√†i ƒê·∫∑t Dependencies

```bash
pip install -r requirements.txt
```

**File `requirements.txt` c·∫ßn c√≥:**

```txt
torch>=1.10.0
torchvision>=0.11.0
timm>=0.6.0
pillow>=9.0.0
pandas>=1.3.0
matplotlib>=3.5.0
seaborn>=0.11.0
scikit-learn>=1.0.0
tqdm>=4.62.0
```

### 4. Ki·ªÉm Tra C√†i ƒê·∫∑t

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
python -c "import timm; print(f'timm: {timm.__version__}')"
```

---

## üìÇ Chu·∫©n B·ªã D·ªØ Li·ªáu

### C·∫•u Tr√∫c Th∆∞ M·ª•c

D·ªØ li·ªáu ph·∫£i c√≥ c·∫•u tr√∫c sau:

```
Paddy-Disease-Classification-final/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv          # File metadata ch·ª©a (path, label, split)
‚îÇ   ‚îú‚îÄ‚îÄ label2id.json         # Mapping t·ª´ t√™n class -> ID
‚îÇ   ‚îú‚îÄ‚îÄ id2label.json         # Mapping t·ª´ ID -> t√™n class
‚îÇ   ‚îú‚îÄ‚îÄ bacterial_leaf_blight/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 0.jpg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1.jpg
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ brown_spot/
‚îÇ   ‚îú‚îÄ‚îÄ healthy/
‚îÇ   ‚îî‚îÄ‚îÄ leaf_blast/
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ train_efficientnet_lite0_ca.py
```

### File `metadata.csv`

```csv
path,label,split
data/bacterial_leaf_blight/0.jpg,bacterial_leaf_blight,train
data/bacterial_leaf_blight/1.jpg,bacterial_leaf_blight,train
data/brown_spot/100.jpg,brown_spot,valid
data/healthy/200.jpg,healthy,test
...
```

**C√°c c·ªôt b·∫Øt bu·ªôc:**

- `path`: ƒê∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi ƒë·∫øn ·∫£nh
- `label`: T√™n class (string)
- `split`: train/valid/test

### File `label2id.json`

```json
{
  "bacterial_leaf_blight": 0,
  "brown_spot": 1,
  "healthy": 2,
  "leaf_blast": 3
}
```

### T·∫°o Metadata (N·∫øu Ch∆∞a C√≥)

```bash
python scripts/prepare_metadata.py \
    --data-dir data \
    --output-dir data \
    --train-ratio 0.7 \
    --valid-ratio 0.15 \
    --test-ratio 0.15
```

---

## üèÉ Training

### Quick Start (M·∫∑c ƒê·ªãnh)

```bash
python scripts/train_efficientnet_lite0_ca.py
```

L·ªánh n√†y s·∫Ω:

- D√πng pretrained weights t·ª´ ImageNet
- Image size = 224
- Batch size = 64
- Epochs = 30
- Early stopping patience = 7
- Base LR = 1e-4, Head LR = 1e-3

### Training ƒê·∫ßy ƒê·ªß (Khuy·∫øn Ngh·ªã)

```bash
python scripts/train_efficientnet_lite0_ca.py \
    --metadata data/metadata.csv \
    --label2id data/label2id.json \
    --output-dir results \
    --image-size 224 \
    --batch-size 64 \
    --epochs 30 \
    --patience 7 \
    --base-lr 1e-4 \
    --head-lr 1e-3 \
    --weight-decay 1e-2 \
    --reduction 16 \
    --dropout 0.2 \
    --pretrained \
    --num-workers 4 \
    --pin-memory \
    --seed 42
```

### Training Nhanh (Debug/Test)

```bash
python scripts/train_efficientnet_lite0_ca.py \
    --train-limit 500 \
    --valid-limit 100 \
    --epochs 5 \
    --batch-size 32
```

### Training T·ª´ Scratch (Kh√¥ng Pretrained)

```bash
python scripts/train_efficientnet_lite0_ca.py \
    --no-pretrained \
    --epochs 50 \
    --base-lr 1e-3 \
    --patience 10
```

### Training Tr√™n CPU

```bash
python scripts/train_efficientnet_lite0_ca.py \
    --device cpu \
    --batch-size 32 \
    --num-workers 2
```

### Training V·ªõi Image Size L·ªõn H∆°n

```bash
python scripts/train_efficientnet_lite0_ca.py \
    --image-size 256 \
    --batch-size 32  # Gi·∫£m batch size v√¨ ·∫£nh l·ªõn h∆°n
```

---

## ‚öôÔ∏è C√°c Tham S·ªë Quan Tr·ªçng

### 1. D·ªØ Li·ªáu

| Tham s·ªë | M·∫∑c ƒë·ªãnh | √ù nghƒ©a |
|---------|----------|---------|
| `--metadata` | `data/metadata.csv` | ƒê∆∞·ªùng d·∫´n file metadata |
| `--label2id` | `data/label2id.json` | ƒê∆∞·ªùng d·∫´n label mapping |
| `--output-dir` | `results` | Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ |

### 2. Model Architecture

| Tham s·ªë | M·∫∑c ƒë·ªãnh | √ù nghƒ©a | Khuy·∫øn ngh·ªã |
|---------|----------|---------|-------------|
| `--reduction` | 16 | Reduction ratio c·ªßa CA block | 16 (balanced), 8 (more params), 32 (lighter) |
| `--dropout` | 0.2 | Dropout rate tr∆∞·ªõc classifier | 0.2-0.3 |
| `--pretrained` | True | D√πng ImageNet weights | Lu√¥n b·∫≠t (tr·ª´ khi train from scratch) |

### 3. Training Hyperparameters

| Tham s·ªë | M·∫∑c ƒë·ªãnh | √ù nghƒ©a | Khuy·∫øn ngh·ªã |
|---------|----------|---------|-------------|
| `--image-size` | 224 | K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o | 224 (nhanh), 256 (ch√≠nh x√°c h∆°n) |
| `--batch-size` | 64 | Batch size | GPU: 64-128, CPU: 16-32 |
| `--epochs` | 30 | S·ªë epoch | 30-50 (pretrained), 80-100 (from scratch) |
| `--patience` | 7 | Early stopping patience | 7-10 |

### 4. Learning Rates

| Tham s·ªë | M·∫∑c ƒë·ªãnh | √ù nghƒ©a | Khuy·∫øn ngh·ªã |
|---------|----------|---------|-------------|
| `--base-lr` | 1e-4 | LR cho backbone | Pretrained: 1e-4 ƒë·∫øn 5e-4, Scratch: 1e-3 |
| `--head-lr` | 1e-3 | LR cho classifier | 5x-10x base-lr |
| `--weight-decay` | 1e-2 | L2 regularization | 1e-2 ƒë·∫øn 5e-2 |

### 5. DataLoader

| Tham s·ªë | M·∫∑c ƒë·ªãnh | √ù nghƒ©a | Khuy·∫øn ngh·ªã |
|---------|----------|---------|-------------|
| `--num-workers` | 4 | S·ªë workers load d·ªØ li·ªáu | CPU cores - 2 |
| `--pin-memory` | False | Pin memory cho GPU | B·∫≠t khi d√πng GPU |

### 6. Debug/Test

| Tham s·ªë | M·∫∑c ƒë·ªãnh | √ù nghƒ©a |
|---------|----------|---------|
| `--train-limit` | None | Gi·ªõi h·∫°n samples train (debug) |
| `--valid-limit` | None | Gi·ªõi h·∫°n samples valid |
| `--device` | Auto | Force CPU/CUDA |
| `--seed` | 42 | Random seed |

---

## üìä K·∫øt Qu·∫£ Mong ƒê·ª£i

### Sau Khi Training

Script s·∫Ω t·∫°o th∆∞ m·ª•c k·∫øt qu·∫£:

```
results/EfficientNet_Lite0_CA_07_10_2025_1430/
‚îú‚îÄ‚îÄ EfficientNet_Lite0_CA_07_10_2025_1430_best.pt  # Checkpoint t·ªët nh·∫•t
‚îú‚îÄ‚îÄ history.json                                    # Training history
‚îú‚îÄ‚îÄ metrics.json                                    # Final metrics
‚îî‚îÄ‚îÄ training_plot.png                               # Loss/accuracy curves
```

### File `metrics.json`

```json
{
  "model_name": "EfficientNet_Lite0_CA_07_10_2025_1430",
  "size_mb": 19.2,
  "valid_acc": 0.9145,
  "valid_f1": 0.9138,
  "fps": 612.3,
  "num_params": 4723456,
  "ckpt_path": "EfficientNet_Lite0_CA_07_10_2025_1430_best.pt"
}
```

### Metrics Chi Ti·∫øt

| Metric | Gi√° tr·ªã Mong ƒê·ª£i |
|--------|------------------|
| **Validation Accuracy** | 90-92% |
| **Validation F1-Score** | 0.90-0.92 |
| **Training Time** | ~30-45 ph√∫t (GPU), ~4-6 gi·ªù (CPU) |
| **FPS (Inference)** | 600+ (GPU), 80+ (CPU) |
| **Model Size** | ~19 MB |

### Training Curves

M·ªôt training th√†nh c√¥ng n√™n c√≥:

- **Train loss:** Gi·∫£m ƒë·ªÅu, kh√¥ng fluctuate qu√° nhi·ªÅu
- **Valid loss:** Gi·∫£m theo train loss, kh√¥ng tƒÉng s·ªõm (overfitting)
- **Train accuracy:** TƒÉng d·∫ßn l√™n 95%+
- **Valid accuracy:** TƒÉng d·∫ßn l√™n 90-92%

---

## üêõ Troubleshooting

### 1. Out of Memory (OOM)

**Tri·ªáu ch·ª©ng:**

```
RuntimeError: CUDA out of memory
```

**Gi·∫£i ph√°p:**

```bash
# Gi·∫£m batch size
python scripts/train_efficientnet_lite0_ca.py --batch-size 32

# Ho·∫∑c gi·∫£m image size
python scripts/train_efficientnet_lite0_ca.py --image-size 192 --batch-size 48

# Ho·∫∑c t·∫Øt pin-memory
python scripts/train_efficientnet_lite0_ca.py --batch-size 32  # Kh√¥ng d√πng --pin-memory
```

### 2. DataLoader Ch·∫≠m

**Tri·ªáu ch·ª©ng:** Training r·∫•t ch·∫≠m, GPU utilization th·∫•p

**Gi·∫£i ph√°p:**

```bash
# TƒÉng num-workers
python scripts/train_efficientnet_lite0_ca.py --num-workers 8 --pin-memory

# Ki·ªÉm tra disk I/O (n√™n d√πng SSD)
```

### 3. Model Kh√¥ng Converge

**Tri·ªáu ch·ª©ng:** Loss kh√¥ng gi·∫£m ho·∫∑c accuracy qu√° th·∫•p

**Gi·∫£i ph√°p:**

```bash
# TƒÉng learning rate
python scripts/train_efficientnet_lite0_ca.py --base-lr 5e-4 --head-lr 2e-3

# Ki·ªÉm tra d·ªØ li·ªáu c√≥ ƒë√∫ng kh√¥ng
python -c "from src.utils.data import build_datasets; datasets = build_datasets(...); print(len(datasets['train']))"

# D√πng pretrained weights
python scripts/train_efficientnet_lite0_ca.py --pretrained
```

### 4. Overfitting

**Tri·ªáu ch·ª©ng:** Train acc >> Valid acc, valid loss tƒÉng s·ªõm

**Gi·∫£i ph√°p:**

```bash
# TƒÉng dropout
python scripts/train_efficientnet_lite0_ca.py --dropout 0.3

# TƒÉng weight decay
python scripts/train_efficientnet_lite0_ca.py --weight-decay 5e-2

# TƒÉng data augmentation (c·∫ßn s·ª≠a transforms)
```

### 5. Training Qu√° Ch·∫≠m Tr√™n CPU

**Gi·∫£i ph√°p:**

```bash
# Gi·∫£m batch size v√† workers
python scripts/train_efficientnet_lite0_ca.py \
    --device cpu \
    --batch-size 16 \
    --num-workers 2

# Ho·∫∑c d√πng Google Colab/Kaggle v·ªõi GPU mi·ªÖn ph√≠
```

### 6. Import Error

**Tri·ªáu ch·ª©ng:**

```
ModuleNotFoundError: No module named 'src'
```

**Gi·∫£i ph√°p:**

```bash
# Ch·∫°y t·ª´ th∆∞ m·ª•c root
cd Paddy-Disease-Classification-final
python scripts/train_efficientnet_lite0_ca.py

# Ho·∫∑c set PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
```

---

## üí° Tips & Tricks

### 1. T·ªëi ∆Øu T·ªëc ƒê·ªô Training

```bash
# GPU v·ªõi batch size l·ªõn
python scripts/train_efficientnet_lite0_ca.py \
    --batch-size 128 \
    --num-workers 8 \
    --pin-memory

# D√πng mixed precision (ƒë√£ c√≥ s·∫µn trong code)
# EfficientNet-Lite0 nh·∫π n√™n c√≥ th·ªÉ d√πng batch r·∫•t l·ªõn
```

### 2. Transfer Learning T·ªët H∆°n

```bash
# Freeze backbone v√†i epoch ƒë·∫ßu, r·ªìi unfreeze
# (C·∫ßn custom code, ch∆∞a c√≥ s·∫µn trong script)

# Ho·∫∑c d√πng differential LR l·ªõn h∆°n
python scripts/train_efficientnet_lite0_ca.py \
    --base-lr 1e-5 \
    --head-lr 1e-3  # 100x head LR
```

### 3. TƒÉng Accuracy

```bash
# TƒÉng image size (trade-off: ch·∫≠m h∆°n)
python scripts/train_efficientnet_lite0_ca.py --image-size 256 --batch-size 32

# Gi·∫£m reduction (nhi·ªÅu params h∆°n)
python scripts/train_efficientnet_lite0_ca.py --reduction 8

# Train l√¢u h∆°n
python scripts/train_efficientnet_lite0_ca.py --epochs 50 --patience 15
```

### 4. Ensemble Models

```bash
# Train nhi·ªÅu models v·ªõi seeds kh√°c nhau
for seed in 42 123 456 789; do
    python scripts/train_efficientnet_lite0_ca.py \
        --seed $seed \
        --model-name EfficientNet_Lite0_CA_seed${seed}
done

# R·ªìi ensemble predictions (c·∫ßn custom code)
```

### 5. Export Cho Production

Sau khi train xong, export model:

```python
import torch
from src.models.backbones import EfficientNet_Lite0_CA

# Load checkpoint
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ckpt = torch.load("results/.../model_best.pt", map_location=device)

# Load v√†o model
model = EfficientNet_Lite0_CA(num_classes=4).to(device)
model.load_state_dict(ckpt["model"])
model.eval()

# Export sang TorchScript (ƒë·ªÉ deploy)
example_input = torch.randn(1, 3, 224, 224).to(device)
traced_model = torch.jit.trace(model, example_input)
traced_model.save("efficientnet_lite0_ca.pt")

# Ho·∫∑c export sang ONNX (cho mobile/edge)
torch.onnx.export(
    model,
    example_input,
    "efficientnet_lite0_ca.onnx",
    opset_version=11,
    input_names=["input"],
    output_names=["output"],
)
```

### 6. Test Tr√™n External Dataset

```bash
# D√πng script test (n·∫øu c√≥)
python test_on_external_dataset.py \
    --model-path results/.../model_best.pt \
    --test-dir path/to/external/data \
    --output test_results/
```

### 7. Benchmark Inference Speed

```python
from src.utils.metrics import fps

# ƒêo FPS
fps_value = fps(
    model=model,
    batch_size=16,
    image_size=224,
    steps=100,
    warmup=20
)
print(f"FPS: {fps_value:.1f}")
```

---

## üìö T√†i Li·ªáu Tham Kh·∫£o

### Papers

- **EfficientNet:** [EfficientNet: Rethinking Model Scaling for CNNs](https://arxiv.org/abs/1905.11946)
- **EfficientNetV2:** [EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/abs/2104.00298)
- **Coordinate Attention:** [Coordinate Attention for Efficient Mobile Network Design](https://arxiv.org/abs/2103.02907)

### Code References

- **timm (PyTorch Image Models):** <https://github.com/huggingface/pytorch-image-models>
- **EfficientNet-Lite:** <https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite>

### Dataset

- **Paddy Doctor:** <https://www.kaggle.com/competitions/paddy-disease-classification>

---

## üìû Li√™n H·ªá & Support

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ ho·∫∑c c√≥ c√¢u h·ªèi:

1. **GitHub Issues:** [Create an issue](https://github.com/tontide1/Rice-leaf-diseases-classification/issues)
2. **Email:** <tontide1@example.com>
3. **Kaggle:** <https://www.kaggle.com/tontide1>

---

## üìÑ License

MIT License - Xem file LICENSE ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.

---

**Ch√∫c b·∫°n training th√†nh c√¥ng! üéâ**
