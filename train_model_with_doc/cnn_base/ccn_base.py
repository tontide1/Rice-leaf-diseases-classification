"""Train Custom CNN models cho Paddy Disease Classification.

Script nÃ y há»— trá»£ training 3 custom CNN architectures:
- LightweightCNN: ~1.2M params, balanced
- TinyPaddyNet: ~0.5M params, cá»±c nháº¹
- CompactCNN: ~1.8M params, accuracy cao hÆ¡n
"""

from __future__ import annotations

import argparse
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional

import torch
from torch import nn
from torch.cuda.amp import GradScaler
from torch.utils.data import DataLoader, Subset

# ThÃªm thÆ° má»¥c src vÃ o path
ROOT_DIR = Path(__file__).resolve().parent
SRC_DIR = ROOT_DIR / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

from src.models.backbones import LightweightCNN, TinyPaddyNet, CompactCNN  # noqa: E402
from src.training import get_param_groups, train_model  # noqa: E402
from src.utils.data import (  # noqa: E402
    TransformConfig,
    build_datasets,
)
from src.utils.metrics import plot_history  # noqa: E402


def parse_args() -> argparse.Namespace:
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser(
        description="Train Custom CNN models trÃªn Paddy Disease dataset"
    )
    
    # Model selection
    parser.add_argument(
        "--model",
        type=str,
        default="lightweight",
        choices=["lightweight", "tiny", "compact"],
        help="Chá»n model architecture: lightweight (1.2M), tiny (0.5M), compact (1.8M)",
    )
    
    # ÄÆ°á»ng dáº«n dá»¯ liá»‡u
    parser.add_argument(
        "--metadata",
        type=Path,
        default=ROOT_DIR / "data/metadata.csv",
        help="ÄÆ°á»ng dáº«n file metadata CSV",
    )
    parser.add_argument(
        "--label2id",
        type=Path,
        default=ROOT_DIR / "data/label2id.json",
        help="ÄÆ°á»ng dáº«n file label2id JSON",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=ROOT_DIR / "results",
        help="ThÆ° má»¥c lÆ°u káº¿t quáº£ training",
    )
    
    # Cáº¥u hÃ¬nh model
    parser.add_argument(
        "--dropout",
        type=float,
        default=0.2,
        help="Dropout probability trÆ°á»›c classifier",
    )
    parser.add_argument(
        "--width-mult",
        type=float,
        default=1.0,
        help="Width multiplier cho LightweightCNN (chá»‰ Ã¡p dá»¥ng cho lightweight)",
    )
    
    # Hyperparameters training
    parser.add_argument(
        "--image-size",
        type=int,
        default=224,
        help="KÃ­ch thÆ°á»›c áº£nh input (224 hoáº·c 256)",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=64,
        help="Batch size cho training",
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=50,
        help="Sá»‘ epoch training (custom CNN cáº§n train lÃ¢u hÆ¡n)",
    )
    parser.add_argument(
        "--patience",
        type=int,
        default=10,
        help="Early stopping patience (<=0 Ä‘á»ƒ táº¯t)",
    )
    
    # Learning rates
    parser.add_argument(
        "--base-lr",
        type=float,
        default=1e-3,
        help="Learning rate chÃ­nh (train from scratch nÃªn cao hÆ¡n)",
    )
    parser.add_argument(
        "--weight-decay",
        type=float,
        default=1e-4,
        help="Weight decay cho optimizer",
    )
    
    # Dataloader settings
    parser.add_argument(
        "--num-workers",
        type=int,
        default=4,
        help="Sá»‘ workers cho DataLoader",
    )
    parser.add_argument(
        "--pin-memory",
        action="store_true",
        default=False,
        help="Pin memory trong DataLoader (tÄƒng tá»‘c GPU)",
    )
    
    # Debug/testing
    parser.add_argument(
        "--train-limit",
        type=int,
        default=None,
        help="Giá»›i háº¡n sá»‘ samples training (Ä‘á»ƒ test nhanh)",
    )
    parser.add_argument(
        "--valid-limit",
        type=int,
        default=None,
        help="Giá»›i háº¡n sá»‘ samples validation",
    )
    
    # Misc
    parser.add_argument(
        "--model-name",
        type=str,
        default=None,
        help="TÃªn model cho logging (máº·c Ä‘á»‹nh: <model>_<timestamp>)",
    )
    parser.add_argument(
        "--scheduler-tmax",
        type=int,
        default=None,
        help="T_max cho CosineAnnealingLR (máº·c Ä‘á»‹nh = epochs)",
    )
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        choices=["cpu", "cuda"],
        help="Force device (máº·c Ä‘á»‹nh: auto-detect)",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Random seed cho reproducibility",
    )
    
    return parser.parse_args()


def make_loader(
    dataset,
    batch_size: int,
    shuffle: bool,
    num_workers: int,
    pin_memory: bool,
    drop_last: bool = False,
) -> DataLoader:
    """Táº¡o PyTorch DataLoader."""
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=drop_last,
        persistent_workers=num_workers > 0,
    )


def maybe_subset(dataset, limit: Optional[int]):
    """Giá»›i háº¡n sá»‘ samples trong dataset (Ä‘á»ƒ debug nhanh)."""
    if limit is None or limit >= len(dataset):
        return dataset
    indices = list(range(limit))
    return Subset(dataset, indices)


def save_results(output_dir: Path, model_name: str, history: dict, metrics: dict) -> None:
    """LÆ°u káº¿t quáº£ training vÃ o file JSON vÃ  plot."""
    run_dir = output_dir / model_name
    run_dir.mkdir(parents=True, exist_ok=True)
    
    # LÆ°u history
    history_path = run_dir / "history.json"
    with open(history_path, "w", encoding="utf-8") as f:
        json.dump(history, f, indent=2, ensure_ascii=False)
    print(f"âœ… ÄÃ£ lÆ°u training history: {history_path}")
    
    # LÆ°u metrics
    metrics_path = run_dir / "metrics.json"
    with open(metrics_path, "w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    print(f"âœ… ÄÃ£ lÆ°u metrics: {metrics_path}")
    
    # Plot training curves
    plot_path = run_dir / "training_plot.png"
    plot_history(history, save_path=str(plot_path))
    print(f"âœ… ÄÃ£ lÆ°u training plot: {plot_path}")
    
    # In ra metrics cuá»‘i cÃ¹ng
    print("\n" + "="*60)
    print("ğŸ“Š Káº¾T QUáº¢ CUá»I CÃ™NG")
    print("="*60)
    print(f"Model: {metrics['model_name']}")
    print(f"Sá»‘ params: {metrics['num_params']:,}")
    print(f"Model size: {metrics['size_mb']:.2f} MB")
    print(f"Valid Accuracy: {metrics['valid_acc']*100:.2f}%")
    print(f"Valid F1-Score: {metrics['valid_f1']:.4f}")
    print(f"FPS (inference): {metrics['fps']:.1f}")
    print(f"Checkpoint: {metrics['ckpt_path']}")
    print("="*60)


def create_model(model_type: str, num_classes: int, dropout: float, 
                width_mult: float = 1.0):
    """Khá»Ÿi táº¡o model theo loáº¡i."""
    if model_type == "lightweight":
        return LightweightCNN(
            num_classes=num_classes,
            dropout=dropout,
            width_mult=width_mult
        )
    elif model_type == "tiny":
        return TinyPaddyNet(
            num_classes=num_classes,
            dropout=dropout
        )
    elif model_type == "compact":
        return CompactCNN(
            num_classes=num_classes,
            dropout=dropout
        )
    else:
        raise ValueError(f"Unknown model type: {model_type}")


def main() -> None:
    """HÃ m main Ä‘á»ƒ train model."""
    args = parse_args()
    
    # Äáº·t random seed
    torch.manual_seed(args.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(args.seed)
    
    # Táº¡o tÃªn model vá»›i timestamp náº¿u khÃ´ng Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
    if args.model_name is None:
        timestamp = datetime.now().strftime("%d_%m_%Y_%H%M")
        model_display = {
            "lightweight": "LightweightCNN",
            "tiny": "TinyPaddyNet",
            "compact": "CompactCNN"
        }
        args.model_name = f"{model_display[args.model]}_{timestamp}"
    
    print(f"ğŸš€ Báº¯t Ä‘áº§u training: {args.model_name}")
    print(f"Model architecture: {args.model}")
    print(f"Device: {args.device or 'auto-detect'}")
    print(f"Image size: {args.image_size}")
    print(f"Batch size: {args.batch_size}")
    print(f"Epochs: {args.epochs}")
    print(f"Learning rate: {args.base_lr}")
    print(f"Dropout: {args.dropout}")
    if args.model == "lightweight":
        print(f"Width multiplier: {args.width_mult}")
    print("")
    
    # Táº¡o datasets
    print("ğŸ“‚ Äang load datasets...")
    cfg = TransformConfig(image_size=args.image_size)
    datasets = build_datasets(
        metadata_path=args.metadata,
        label2id_path=args.label2id,
        cfg=cfg,
        splits=("train", "valid"),
    )
    
    num_classes = len(datasets["train"].label2id) if hasattr(datasets["train"], "label2id") else 4
    print(f"âœ… ÄÃ£ load datasets: {len(datasets['train'])} train, {len(datasets['valid'])} valid")
    print(f"Sá»‘ classes: {num_classes}")
    
    # Ãp dá»¥ng limit náº¿u cÃ³ (Ä‘á»ƒ debug)
    train_dataset = maybe_subset(datasets["train"], args.train_limit)
    valid_dataset = maybe_subset(datasets["valid"], args.valid_limit)
    
    if args.train_limit or args.valid_limit:
        print(f"âš ï¸  Debug mode: train={len(train_dataset)}, valid={len(valid_dataset)}")
    
    # Táº¡o dataloaders
    train_loader = make_loader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=args.pin_memory,
        drop_last=True,
    )
    valid_loader = make_loader(
        valid_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=args.pin_memory,
        drop_last=False,
    )
    
    # Khá»Ÿi táº¡o model
    device = torch.device(args.device) if args.device else torch.device(
        "cuda" if torch.cuda.is_available() else "cpu"
    )
    print(f"\nğŸ”§ Khá»Ÿi táº¡o model {args.model}...")
    print(f"Device: {device}")
    
    model = create_model(
        model_type=args.model,
        num_classes=num_classes,
        dropout=args.dropout,
        width_mult=args.width_mult
    ).to(device)
    
    # In sá»‘ params
    num_params = sum(p.numel() for p in model.parameters())
    num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"âœ… Model initialized:")
    print(f"   - Total params: {num_params:,}")
    print(f"   - Trainable params: {num_trainable:,}")
    
    # Loss function
    criterion = nn.CrossEntropyLoss()
    
    # Optimizer - Ä‘Æ¡n giáº£n hÆ¡n vÃ¬ train from scratch
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=args.base_lr,
        weight_decay=args.weight_decay
    )
    print(f"âœ… Optimizer: AdamW (lr={args.base_lr}, wd={args.weight_decay})")
    
    # Scheduler
    t_max = args.scheduler_tmax or args.epochs
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=max(1, t_max)
    )
    print(f"âœ… Scheduler: CosineAnnealingLR (T_max={t_max})")
    
    # Gradient scaler cho mixed precision
    scaler = GradScaler(enabled=device.type == "cuda")
    
    # Early stopping
    patience = args.patience if args.patience > 0 else None
    if patience:
        print(f"âœ… Early stopping: patience={patience}")
    
    # Training
    print(f"\n{'='*60}")
    print("ğŸ¯ Báº®T Äáº¦U TRAINING")
    print(f"{'='*60}\n")
    
    history, metrics = train_model(
        model_name=args.model_name,
        model=model,
        train_loader=train_loader,
        valid_loader=valid_loader,
        criterion=criterion,
        optimizer=optimizer,
        scaler=scaler,
        scheduler=scheduler,
        gpu_aug=None,
        MEAN=None,
        STD=None,
        epochs=args.epochs,
        patience=patience,
        fps_image_size=args.image_size,
    )
    
    # LÆ°u káº¿t quáº£
    print(f"\n{'='*60}")
    print("ğŸ’¾ LÆ¯U Káº¾T QUáº¢")
    print(f"{'='*60}\n")
    save_results(args.output_dir, args.model_name, history, metrics)
    
    print(f"\nâœ… HOÃ€N THÃ€NH! Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {args.output_dir / args.model_name}")


if __name__ == "__main__":
    main()
